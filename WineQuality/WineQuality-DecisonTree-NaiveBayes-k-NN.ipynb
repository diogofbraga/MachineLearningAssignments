{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wine Quality\n",
    "\n",
    "**Data Set Information:**\n",
    "TBC\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "**-type:** red wine or white wine, nominal qunatity; <br>\n",
    "**-fixed acidity:** grams of tataric acid per 100ml, ratio qunatity; <br>\n",
    "**-volatile acidity:** grams of acetic acid per liter of wine, ratio qunatity; <br>\n",
    "**-citric acid:** grams per liter, ratio qunatity; <br>\n",
    "**-residual sugar:** grams per liter, ratio qunatity; <br>\n",
    "**-chlorides:** grams of sodium chloride per liter, ratio qunatity; <br>\n",
    "**-free sulfur dioxide:** milligrams per liter, ratio qunatity; <br>\n",
    "**-total sulfur dioxide:** milligrams per liter, ratio qunatity; <br>\n",
    "**-density:** grams per cubic centimeter, ratio qunatity; <br>\n",
    "**-pH:** ratio qunatity; <br>\n",
    "**-sulphates:** grams of potassium sulfate per liter, ratio qunatity; <br>\n",
    "**-alcohol:** vol.%, ratio qunatity; <br>\n",
    "**-quality:** Output variable, score between 0 and 10, subjective(?), ordinal qunantity \n",
    "\n",
    "Preprocessing:\n",
    "Combine two .csv files (one for red wine, one for white wine) into one file with the new attribute \"type\".\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Data Preparation\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wineQualityBothTypes.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>white</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>white</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>white</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>white</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>white</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0       red            7.4              0.70         0.00             1.9   \n",
       "1       red            7.8              0.88         0.00             2.6   \n",
       "2       red            7.8              0.76         0.04             2.3   \n",
       "3       red           11.2              0.28         0.56             1.9   \n",
       "4       red            7.4              0.70         0.00             1.9   \n",
       "...     ...            ...               ...          ...             ...   \n",
       "6492  white            6.2              0.21         0.29             1.6   \n",
       "6493  white            6.6              0.32         0.36             8.0   \n",
       "6494  white            6.5              0.24         0.19             1.2   \n",
       "6495  white            5.5              0.29         0.30             1.1   \n",
       "6496  white            6.0              0.21         0.38             0.8   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "1         0.098                 25.0                  67.0  0.99680  3.20   \n",
       "2         0.092                 15.0                  54.0  0.99700  3.26   \n",
       "3         0.075                 17.0                  60.0  0.99800  3.16   \n",
       "4         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6492      0.039                 24.0                  92.0  0.99114  3.27   \n",
       "6493      0.047                 57.0                 168.0  0.99490  3.15   \n",
       "6494      0.041                 30.0                 111.0  0.99254  2.99   \n",
       "6495      0.022                 20.0                 110.0  0.98869  3.34   \n",
       "6496      0.020                 22.0                  98.0  0.98941  3.26   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "0          0.56      9.4        5  \n",
       "1          0.68      9.8        5  \n",
       "2          0.65      9.8        5  \n",
       "3          0.58      9.8        6  \n",
       "4          0.56      9.4        5  \n",
       "...         ...      ...      ...  \n",
       "6492       0.50     11.2        6  \n",
       "6493       0.46      9.6        5  \n",
       "6494       0.46      9.4        6  \n",
       "6495       0.38     12.8        7  \n",
       "6496       0.32     11.8        6  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   type                  6497 non-null   object \n",
      " 1   fixed acidity         6497 non-null   float64\n",
      " 2   volatile acidity      6497 non-null   float64\n",
      " 3   citric acid           6497 non-null   float64\n",
      " 4   residual sugar        6497 non-null   float64\n",
      " 5   chlorides             6497 non-null   float64\n",
      " 6   free sulfur dioxide   6497 non-null   float64\n",
      " 7   total sulfur dioxide  6497 non-null   float64\n",
      " 8   density               6497 non-null   float64\n",
      " 9   pH                    6497 non-null   float64\n",
      " 10  sulphates             6497 non-null   float64\n",
      " 11  alcohol               6497 non-null   float64\n",
      " 12  quality               6497 non-null   int64  \n",
      "dtypes: float64(11), int64(1), object(1)\n",
      "memory usage: 660.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378  \n",
       "std       0.160787     0.148806     1.192712     0.873255  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type\n",
       "count    6497\n",
       "unique      2\n",
       "top     white\n",
       "freq     4898"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                    0\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into red and white again\n",
    "dataRed = data.loc[data['type'] == 'red']\n",
    "dataWhite = data.loc[data['type'] == 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "bins = np.arange(data['quality'].min(), data['quality'].max()+1)\n",
    "plt.hist(data['quality'], bins=bins, align='left')\n",
    "plt.title(\"Both Types\")\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Split into white wine and red wine\n",
    "White wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "dataWhite = data.loc[data['type'] == 'white']\n",
    "bins = np.arange(dataWhite['quality'].min(), dataWhite['quality'].max()+1)\n",
    "plt.hist(dataWhite['quality'], bins=bins, align='left')\n",
    "plt.title(\"White Wine\")\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Red wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "bins = np.arange(dataRed['quality'].min(), dataRed['quality'].max()+1)\n",
    "plt.hist(dataRed['quality'], bins=bins, align='left')\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Acidity vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['fixed acidity'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('fixed acidity [g(tataric acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['fixed acidity'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('fixed acidity [g(tataric acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['fixed acidity'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('fixed acidity [g(tataric acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatile Acidity vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['volatile acidity'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('volatile acidity [g(acetic acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['volatile acidity'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('volatile acidity [g(acetic acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['volatile acidity'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('volatile acidity [g(acetic acid)/100ml]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citric Acid vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['citric acid'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('citric acid [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['citric acid'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('citric acid [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['citric acid'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('citric acid [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Sugar vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['residual sugar'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('residual sugar [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['residual sugar'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('residual sugar [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['residual sugar'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('residual sugar [g/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chlorides vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['chlorides'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('chlorides [g(sodium chloride)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['chlorides'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('chlorides [g(sodium chloride)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['chlorides'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('chlorides [g(sodium chloride)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Sulfur Dioxide vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['free sulfur dioxide'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('free sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['free sulfur dioxide'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('free sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['free sulfur dioxide'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('free sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Sulfur Dioxide vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['total sulfur dioxide'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('total sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['total sulfur dioxide'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('total sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['total sulfur dioxide'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('total sulfur dioxide [mg/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['density'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('density [g/cm³]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['density'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('density [g/cm³]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['density'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('density [g/cm³]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pH value vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['pH'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('pH')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['pH'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('pH')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['pH'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('pH')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sulphates vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['sulphates'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('sulphates [g(potassium sulfate)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['sulphates'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('sulphates [g(potassium sulfate)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['sulphates'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('sulphates [g(potassium sulfate)/l]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcohol Content vs. Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "#sns.jointplot(data['fixed acidity'], data['quality'], kind='reg')\n",
    "plt.scatter(data['alcohol'], data['quality'])\n",
    "plt.title(\"Both Types\")\n",
    "plt.xlabel('alcohol [vol%]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataRed['alcohol'], dataRed['quality'])\n",
    "plt.title(\"Red Wine\")\n",
    "plt.xlabel('alcohol [vol%]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(dataWhite['alcohol'], dataWhite['quality'])\n",
    "plt.title(\"White Wine\")\n",
    "plt.xlabel('alcohol [vol%]')\n",
    "plt.ylabel('quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first convert the strings 'white' and 'red' to 0 and 1 respectively\n",
    "mapping = {'white': 0, 'red': 1}\n",
    "data = data.replace({'type': mapping})\n",
    "\n",
    "#Then split data into red and white again with that mapping\n",
    "dataWhite = dataWhite.replace({'type': mapping})\n",
    "dataRed = dataRed.replace({'type': mapping})\n",
    "\n",
    "#split the data in attributes and class\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "#split the data in attributes and class\n",
    "XWhite = dataWhite.drop('quality', axis=1)\n",
    "yWhite = dataWhite['quality']\n",
    "\n",
    "XRed = dataRed.drop('quality', axis=1)\n",
    "yRed = dataRed['quality']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.1) Feature Selection \n",
    "\n",
    "**Choose one of the methods:**\n",
    "1. SelectPercentile (chi2)\n",
    "2. SelectFromModel (LinearSVC)\n",
    "3. SelectFromModel (LogisticRegression)\n",
    "3. SelectFromModel (ExtraTreesClassifier)\n",
    "\n",
    "## 2.2) Data Pre-processing\n",
    "\n",
    "**Choose one of the methods:**\n",
    "1. Standardization (StandardScaler)\n",
    "2. Standardization (RobustScaler)\n",
    "3. MinMaxScaler\n",
    "4. Normalization\n",
    "\n",
    "## 2.3)Outliers Detection using mathematical function Z-Score\n",
    "\n",
    "\n",
    "### All three features included in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelection(XCurr, yCurr, featureselection_method, preprocessing_method):\n",
    "    if featureselection_method == 1:\n",
    "        selection = SelectPercentile(chi2, percentile=5)\n",
    "    elif featureselection_method == 2:\n",
    "        clf = LinearSVC()\n",
    "        #clf = LinearSVC(C=0.1, penalty=\"l1\", dual=False).fit(X, y)\n",
    "        selection = SelectFromModel(clf, prefit=False)\n",
    "    elif featureselection_method == 3:\n",
    "        clf = LogisticRegression()\n",
    "        #clf = LogisticRegression(C=0.2, penalty=\"l2\", dual=False, max_iter=200).fit(X, y)\n",
    "        selection = SelectFromModel(clf, prefit=False)\n",
    "    elif featureselection_method == 4:\n",
    "        clf = ExtraTreesClassifier(n_estimators=50).fit(XCurr, yCurr)\n",
    "        selection = SelectFromModel(clf, prefit=False)      \n",
    "\n",
    "    clf.feature_importances_ \n",
    "    X_transformed = selection.fit_transform(XCurr, yCurr)\n",
    "    columns = np.asarray(XCurr.columns.values)\n",
    "    support = np.asarray(selection.get_support())\n",
    "    columns_with_support = columns[support]\n",
    "    print(\"X_transformed.shape\",X_transformed.shape)\n",
    "    print(\"selected attributes: \", columns_with_support)\n",
    "    \n",
    "    #Data Pre-processing:\n",
    "    if preprocessing_method == 1:\n",
    "        scaler = StandardScaler()\n",
    "        scaler = scaler.fit(X_transformed)\n",
    "        X_scaled = scaler.transform(X_transformed)\n",
    "    elif preprocessing_method == 2:\n",
    "        scaler = RobustScaler()\n",
    "        scaler = scaler.fit(X_transformed)\n",
    "        X_scaled = scaler.transform(X_transformed)\n",
    "    elif preprocessing_method == 3:\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaler = scaler.fit(X_transformed)\n",
    "        X_scaled = scaler.transform(X_transformed)\n",
    "    elif preprocessing_method == 4:\n",
    "        scaler = preprocessing.Normalizer()\n",
    "        scaler = scaler.fit(X_transformed)\n",
    "        X_scaled = scaler.transform(X_transformed)\n",
    "    print(\"X_scaled = \",X_scaled)\n",
    "    \n",
    "    \n",
    "    #Outlier Detection:\n",
    "    z = np.abs(stats.zscore(X_scaled))\n",
    "    threshold = 20\n",
    "    outliers_rows = np.where(z > threshold)\n",
    "    print(\"\\n z > threshold = \", np.where(z > threshold))\n",
    "    # The first array contains the list of row numbers and second array respective column numbers\n",
    "    print(\"\\n number of outliers = \",len(set(outliers_rows[0])))\n",
    "    \n",
    "    #Remove Ouliers\n",
    "    #X_prepared = X_scaled[(np.abs(stats.zscore(X_scaled)) < threshold).all(axis=1)]\n",
    "    #X_prepared.shape\n",
    "    #y = y.to_numpy()\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_scaled, yCurr, test_size=0.30)\n",
    "    #return(X_train, X_test, y_train, y_test)\n",
    "    return(X_scaled, yCurr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureselection_method = 4\n",
    "preprocessing_method = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------both types ------------------\n",
      "\n",
      "X_transformed.shape (6497, 6)\n",
      "selected attributes:  ['volatile acidity' 'free sulfur dioxide' 'total sulfur dioxide' 'density'\n",
      " 'sulphates' 'alcohol']\n",
      "X_scaled =  [[ 2.18883292 -1.10013986 -1.44635852  1.03499282  0.19309677 -0.91546416]\n",
      " [ 3.28223494 -0.31132009 -0.86246863  0.70148631  0.99957862 -0.58006813]\n",
      " [ 2.55330026 -0.87476278 -1.09248586  0.76818761  0.79795816 -0.58006813]\n",
      " ...\n",
      " [-0.6054167  -0.02959874 -0.08394876 -0.71925142 -0.47897144 -0.91546416]\n",
      " [-0.30169391 -0.59304143 -0.10164239 -2.00325148 -1.016626    1.9354021 ]\n",
      " [-0.78765037 -0.48035289 -0.31396599 -1.7631268  -1.41986693  1.09691202]]\n",
      "\n",
      " z > threshold =  (array([], dtype=int64), array([], dtype=int64))\n",
      "\n",
      " number of outliers =  0\n",
      "\n",
      "--------------------red wine -------------------\n",
      "\n",
      "X_transformed.shape (1599, 6)\n",
      "selected attributes:  ['volatile acidity' 'citric acid' 'total sulfur dioxide' 'density'\n",
      " 'sulphates' 'alcohol']\n",
      "X_scaled =  [[ 0.96187667 -1.39147228 -0.37913269  0.55827446 -0.57920652 -0.96024611]\n",
      " [ 1.96744245 -1.39147228  0.62436323  0.02826077  0.1289504  -0.58477711]\n",
      " [ 1.29706527 -1.18607043  0.22904665  0.13426351 -0.04808883 -0.58477711]\n",
      " ...\n",
      " [-0.09955388 -0.72391627 -0.19667889 -0.53355375  0.54204194  0.54162988]\n",
      " [ 0.65462046 -0.77526673 -0.07504302 -0.67665745  0.30598963 -0.20930812]\n",
      " [-1.21684919  1.02199944 -0.13586095 -0.66605717  0.01092425  0.54162988]]\n",
      "\n",
      " z > threshold =  (array([], dtype=int64), array([], dtype=int64))\n",
      "\n",
      " number of outliers =  0\n",
      "\n",
      "-------------------white wine------------------\n",
      "\n",
      "X_transformed.shape (4898, 8)\n",
      "selected attributes:  ['volatile acidity' 'citric acid' 'residual sugar' 'free sulfur dioxide'\n",
      " 'total sulfur dioxide' 'density' 'pH' 'alcohol']\n",
      "X_scaled =  [[-0.0817699   0.2132802   2.82134917 ...  2.33151201 -1.24692128\n",
      "  -1.39315246]\n",
      " [ 0.21589563  0.04800112 -0.94476527 ... -0.00915417  0.74002864\n",
      "  -0.82427568]\n",
      " [ 0.01745194  0.54383836  0.10028219 ...  0.3586648   0.47510198\n",
      "  -0.33666701]\n",
      " ...\n",
      " [-0.37943543 -1.19159198 -1.02363678 ... -0.49735026 -1.31315295\n",
      "  -0.90554379]\n",
      " [ 0.11667379 -0.28255704 -1.04335466 ... -1.78471666  1.0049553\n",
      "   1.85757201]\n",
      " [-0.67710097  0.37855928 -1.10250829 ... -1.54396243  0.47510198\n",
      "   1.04489089]]\n",
      "\n",
      " z > threshold =  (array([], dtype=int64), array([], dtype=int64))\n",
      "\n",
      " number of outliers =  0\n"
     ]
    }
   ],
   "source": [
    "print('\\n-------------------both types ------------------\\n')\n",
    "X, y = featureSelection(X, y, featureselection_method, preprocessing_method)\n",
    "\n",
    "print('\\n--------------------red wine -------------------\\n')\n",
    "XRed, yRed = featureSelection(XRed, yRed, featureselection_method, preprocessing_method)\n",
    "\n",
    "print('\\n-------------------white wine------------------\\n')\n",
    "XWhite, yWhite = featureSelection(XWhite, yWhite, featureselection_method, preprocessing_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = 1\n",
    "\n",
    "d = {}\n",
    "\n",
    "d[\"Logistic Regression\"] = LogisticRegression(max_iter=200)\n",
    "d[\"Gaussian Naive Bayes\"] = GaussianNB()\n",
    "\n",
    "d[\"KNearest Neighbors (\"+ str(NN) + \")\"] = KNeighborsClassifier(n_neighbors=NN)\n",
    "\n",
    "d[\"SVM rbf\"] = SVC()\n",
    "d[\"SGD Classifier\"] = SGDClassifier()\n",
    "\n",
    "d[\"Decision Tree\"] = DecisionTreeClassifier()\n",
    "\n",
    "d[\"Random Forest\"] = RandomForestClassifier()\n",
    "\n",
    "d[\"Multi-layer Perceptron Classifier\"] = MLPClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Remark:\n",
    "Depending on the split of test and training set sometimes the ranking of the accuracy of the 8 claassifiers changes a bit. therefore I decided to run the classifiers with standard setting N times with different test/training set splits. \n",
    "Then from the average accuracy I chose the top three. \n",
    "For those three i then do a hyperparameter optimization.\n",
    "This way it is easier to pick three classifiers for the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Comparison of Classifiers with standard settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareClassifiers(X, y, d):\n",
    "    N = 15\n",
    "    \n",
    "    scoreList = [0]*len(d.items())\n",
    "    highScoreList = [0]*len(d.items())\n",
    "    nameList = ['a']*len(d.items())\n",
    "    timeList = [0]*len(d.items())\n",
    "    \n",
    "    for i in range(0,N):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "        \n",
    "        counter = 0\n",
    "        for name, clf in d.items():\n",
    "            start = time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            end = time.time()\n",
    "            timeList[counter] = timeList[counter] + (end - start)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            scoreList[counter] = scoreList[counter] + score\n",
    "            if score > highScoreList[counter]:\n",
    "                highScoreList[counter] = score\n",
    "            nameList[counter] = name #overwrites n times but whatever \n",
    "            #print(\"i = \", i, \" counter = \", counter, \"score = \", score, \"name = \", name, \"time = \", end - start)\n",
    "            counter += 1\n",
    " \n",
    "    scoreList[:] = [x / N for x in scoreList]\n",
    "    timeList[:] = [x / N for x in timeList] \n",
    "    \n",
    "    ranking = sorted(zip(scoreList,nameList,highScoreList,timeList))[::-1]\n",
    "    print(ranking)\n",
    "    print(\"\\nClassifiers from best to worst:\")\n",
    "    for i in range(0, len(ranking)):\n",
    "        print(i+1, ') {:34} averageScore: {:.5} bestScore: {:.5} averageTime: {:.5} s'.format(ranking[i][1], str(ranking[i][0]), str(ranking[i][2]), str(ranking[i][3])))\n",
    "        #print(ranking[i][1], ranking[i][0],ranking[i][2], ranking[i][3])\n",
    "    return(y_test, y_train, X_test, X_train, ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#old version:\n",
    "y_test, y_train, X_test, X_train = train_test_split(X, y, test_size=0.20)\n",
    "scoreList = []\n",
    "nameList = []\n",
    "counter = 0\n",
    "\n",
    "for name, clf in d.items():\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scoreList.append(accuracy_score(y_test, y_pred))\n",
    "    nameList.append(name)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"\\n--------------\",name,\"---------------\\n\")\n",
    "    print(\"- Accuracy: %f\" % score, \"- Time: %0.2f\" % (end - start), \"seconds\")\n",
    "    print(\"\\n Number of mislabeled points out of a total %d points : %d \\n\\n\"% (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "print(\"###############\")\n",
    "ranking = sorted(zip(scoreList,nameList))[::-1]\n",
    "#print(sorted(zip(scoreList,nameList)))\n",
    "print(\"\\nClassifiers from best to worst:\")\n",
    "for i in range(0, len(ranking)):\n",
    "    print(i+1, ') {0:35} score: {1}'.format(ranking[i][1], ranking[i][0]))\n",
    "\n",
    "#return(y_test, y_train, X_test, X_train, ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1) Both Wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6632871794871795, 'Random Forest', 0.683076923076923, 0.635870385169983), (0.6041538461538464, 'KNearest Neighbors (1)', 0.6287179487179487, 0.06420836687088012), (0.5833076923076922, 'Decision Tree', 0.6092307692307692, 0.01921846866607666), (0.5589743589743589, 'Multi-layer Perceptron Classifier', 0.5851282051282052, 8.664347414970399), (0.5542153846153844, 'SVM rbf', 0.5733333333333334, 1.0227362895011902), (0.5394769230769233, 'Logistic Regression', 0.5641025641025641, 0.3410611534118652), (0.5024564102564102, 'SGD Classifier', 0.5425641025641026, 0.05513713598251343), (0.48352307692307706, 'Gaussian Naive Bayes', 0.5102564102564102, 0.002738757133483887)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.663 bestScore: 0.683 averageTime: 0.635 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.604 bestScore: 0.628 averageTime: 0.064 s\n",
      "3 ) Decision Tree                      averageScore: 0.583 bestScore: 0.609 averageTime: 0.019 s\n",
      "4 ) Multi-layer Perceptron Classifier  averageScore: 0.558 bestScore: 0.585 averageTime: 8.664 s\n",
      "5 ) SVM rbf                            averageScore: 0.554 bestScore: 0.573 averageTime: 1.022 s\n",
      "6 ) Logistic Regression                averageScore: 0.539 bestScore: 0.564 averageTime: 0.341 s\n",
      "7 ) SGD Classifier                     averageScore: 0.502 bestScore: 0.542 averageTime: 0.055 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.483 bestScore: 0.510 averageTime: 0.002 s\n"
     ]
    }
   ],
   "source": [
    "y_test, y_train, X_test, X_train, rankingBoth = compareClassifiers(X, y, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2) Red Wine only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6730624999999999, 'Random Forest', 0.725, 0.25492878913879397), (0.615541666666667, 'KNearest Neighbors (1)', 0.675, 0.022631077766418456), (0.6066041666666667, 'SVM rbf', 0.6479166666666667, 0.09084071874618531), (0.6003125, 'Decision Tree', 0.6583333333333333, 0.004735956192016602), (0.5957083333333333, 'Multi-layer Perceptron Classifier', 0.6375, 4.289286739826203), (0.5891666666666666, 'Logistic Regression', 0.6375, 0.06052438497543335), (0.5816875000000001, 'Gaussian Naive Bayes', 0.6229166666666667, 0.0020508909225463866), (0.53, 'SGD Classifier', 0.5875, 0.01654426097869873)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.673 bestScore: 0.725 averageTime: 0.254 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.615 bestScore: 0.675 averageTime: 0.022 s\n",
      "3 ) SVM rbf                            averageScore: 0.606 bestScore: 0.647 averageTime: 0.090 s\n",
      "4 ) Decision Tree                      averageScore: 0.600 bestScore: 0.658 averageTime: 0.004 s\n",
      "5 ) Multi-layer Perceptron Classifier  averageScore: 0.595 bestScore: 0.637 averageTime: 4.289 s\n",
      "6 ) Logistic Regression                averageScore: 0.589 bestScore: 0.637 averageTime: 0.060 s\n",
      "7 ) Gaussian Naive Bayes               averageScore: 0.581 bestScore: 0.622 averageTime: 0.002 s\n",
      "8 ) SGD Classifier                     averageScore: 0.53 bestScore: 0.587 averageTime: 0.016 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "yRed_test, yRed_train, XRed_test, XRed_train, rankingRed = compareClassifiers(XRed, yRed, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3) White Wine only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6655782312925171, 'Random Forest', 0.6870748299319728, 0.4902655172348023), (0.6068911564625848, 'KNearest Neighbors (1)', 0.6312925170068027, 0.05667234897613525), (0.5845170068027211, 'Decision Tree', 0.6142857142857143, 0.018590912818908692), (0.5542108843537414, 'SVM rbf', 0.582312925170068, 0.6213712024688721), (0.5541224489795918, 'Multi-layer Perceptron Classifier', 0.5816326530612245, 8.58089510679245), (0.529047619047619, 'Logistic Regression', 0.5544217687074829, 0.29793455839157107), (0.4782244897959183, 'SGD Classifier', 0.5231292517006803, 0.050176618099212644), (0.4547755102040817, 'Gaussian Naive Bayes', 0.4850340136054422, 0.0025214886665344237)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.665 bestScore: 0.687 averageTime: 0.490 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.606 bestScore: 0.631 averageTime: 0.056 s\n",
      "3 ) Decision Tree                      averageScore: 0.584 bestScore: 0.614 averageTime: 0.018 s\n",
      "4 ) SVM rbf                            averageScore: 0.554 bestScore: 0.582 averageTime: 0.621 s\n",
      "5 ) Multi-layer Perceptron Classifier  averageScore: 0.554 bestScore: 0.581 averageTime: 8.580 s\n",
      "6 ) Logistic Regression                averageScore: 0.529 bestScore: 0.554 averageTime: 0.297 s\n",
      "7 ) SGD Classifier                     averageScore: 0.478 bestScore: 0.523 averageTime: 0.050 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.454 bestScore: 0.485 averageTime: 0.002 s\n"
     ]
    }
   ],
   "source": [
    "yWhite_test, yWhite_train, XWhite_test, XWhite_train, rankingWhite = compareClassifiers(XWhite, yWhite, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameterOptimization(classifierName, param_grid, ranking, y_test, y_train, X_test, X_train):\n",
    "    names = [j for i,j,k,l in ranking]\n",
    "    index = names.index(classifierName)\n",
    "    #print(ranking[index][1])\n",
    "\n",
    "    start = time.time()\n",
    "    clf_gridsearch = GridSearchCV(d.get(ranking[index][1]), param_grid, verbose=0)\n",
    "    clf_gridsearch.fit(X_train, y_train)\n",
    "    print(clf_gridsearch.best_params_)\n",
    "    predictions = clf_gridsearch.predict(X_test)\n",
    "    #print(\"test =\",predictions)\n",
    "    score_gridsearch = accuracy_score(y_test, predictions)\n",
    "    end = time.time()\n",
    "    print(\"GridSearchCV - Accuracy: %f\" % score_gridsearch, \"- Time: %0.2f\" % (end - start), \"seconds\")\n",
    "    print(\"Previous best Accuracy: \", ranking[index][2])\n",
    "   \n",
    "    print(\"\\n\\nAdditional statistics for prediction using best parameters:\\n\")\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d \\n\"% (X_test.shape[0], (y_test != predictions).sum()))\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, predictions))\n",
    "    print(\"Classsification Report: \\n\",classification_report(y_test, predictions))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defaultPrediction(clf, y_test, y_train, X_test, X_train):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"accuracy with standard parameters:\",accuracy_score(y_test, y_pred))    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1) RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth': [10, 50, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2]}\n",
    "#takes very long to calculate, if param grid is too large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.1) Both Wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6611282051282051, 'Random Forest', 0.6676923076923077, 0.6193455219268799), (0.6033504273504274, 'KNearest Neighbors (1)', 0.6164102564102564, 0.06026503245035807), (0.5858461538461538, 'Decision Tree', 0.6087179487179487, 0.018300247192382813), (0.5549401709401709, 'Multi-layer Perceptron Classifier', 0.58, 8.645585664113362), (0.549162393162393, 'SVM rbf', 0.563076923076923, 0.9734248638153076), (0.5327863247863248, 'Logistic Regression', 0.5512820512820513, 0.3160899957021078), (0.491076923076923, 'SGD Classifier', 0.5328205128205128, 0.049910879135131835), (0.48140170940170945, 'Gaussian Naive Bayes', 0.49743589743589745, 0.002522182464599609)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.661 bestScore: 0.667 averageTime: 0.619 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.603 bestScore: 0.616 averageTime: 0.060 s\n",
      "3 ) Decision Tree                      averageScore: 0.585 bestScore: 0.608 averageTime: 0.018 s\n",
      "4 ) Multi-layer Perceptron Classifier  averageScore: 0.554 bestScore: 0.58 averageTime: 8.645 s\n",
      "5 ) SVM rbf                            averageScore: 0.549 bestScore: 0.563 averageTime: 0.973 s\n",
      "6 ) Logistic Regression                averageScore: 0.532 bestScore: 0.551 averageTime: 0.316 s\n",
      "7 ) SGD Classifier                     averageScore: 0.491 bestScore: 0.532 averageTime: 0.049 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.481 bestScore: 0.497 averageTime: 0.002 s\n",
      "accuracy with standard parameters: 0.6517948717948718\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "GridSearchCV - Accuracy: 0.665641 - Time: 71.12 seconds\n",
      "Previous best Accuracy:  0.6676923076923077\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1950 points : 652 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   1   5   3   1   0]\n",
      " [  0   6  42  17   1   0]\n",
      " [  0   5 452 158   5   1]\n",
      " [  0   0 158 646  54   0]\n",
      " [  0   0  16 154 170   2]\n",
      " [  0   0   1  19   9  24]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.50      0.09      0.15        66\n",
      "           5       0.67      0.73      0.70       621\n",
      "           6       0.65      0.75      0.70       858\n",
      "           7       0.71      0.50      0.58       342\n",
      "           8       0.89      0.45      0.60        53\n",
      "\n",
      "    accuracy                           0.67      1950\n",
      "   macro avg       0.57      0.42      0.46      1950\n",
      "weighted avg       0.66      0.67      0.65      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_train, X_test, X_train, rankingBoth = compareClassifiers(X, y, d)\n",
    "defaultPrediction(RandomForestClassifier(), y_test, y_train, X_test, X_train)\n",
    "hyperparameterOptimization('Random Forest', param_grid, rankingBoth, y_test, y_train, X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2) Red Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6790277777777778, 'Random Forest', 0.725, 0.2629309018452962), (0.6219444444444445, 'KNearest Neighbors (1)', 0.6520833333333333, 0.0239318052927653), (0.6175, 'SVM rbf', 0.64375, 0.08888880411783855), (0.6079166666666665, 'Decision Tree', 0.6416666666666667, 0.005825519561767578), (0.605138888888889, 'Multi-layer Perceptron Classifier', 0.6333333333333333, 4.589286470413208), (0.5977777777777779, 'Logistic Regression', 0.6208333333333333, 0.06626752217610678), (0.5845833333333332, 'Gaussian Naive Bayes', 0.63125, 0.002061939239501953), (0.5266666666666666, 'SGD Classifier', 0.5833333333333334, 0.017778396606445312)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.679 bestScore: 0.725 averageTime: 0.262 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.621 bestScore: 0.652 averageTime: 0.023 s\n",
      "3 ) SVM rbf                            averageScore: 0.617 bestScore: 0.643 averageTime: 0.088 s\n",
      "4 ) Decision Tree                      averageScore: 0.607 bestScore: 0.641 averageTime: 0.005 s\n",
      "5 ) Multi-layer Perceptron Classifier  averageScore: 0.605 bestScore: 0.633 averageTime: 4.589 s\n",
      "6 ) Logistic Regression                averageScore: 0.597 bestScore: 0.620 averageTime: 0.066 s\n",
      "7 ) Gaussian Naive Bayes               averageScore: 0.584 bestScore: 0.631 averageTime: 0.002 s\n",
      "8 ) SGD Classifier                     averageScore: 0.526 bestScore: 0.583 averageTime: 0.017 s\n",
      "accuracy with standard parameters: 0.6833333333333333\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "GridSearchCV - Accuracy: 0.691667 - Time: 27.00 seconds\n",
      "Previous best Accuracy:  0.725\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 480 points : 148 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   0]\n",
      " [  0   0   8   8   0   0]\n",
      " [  0   0 174  27   2   0]\n",
      " [  0   0  55 135  16   0]\n",
      " [  0   0   4  21  23   2]\n",
      " [  0   0   0   3   1   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.72      0.86      0.78       203\n",
      "           6       0.70      0.66      0.67       206\n",
      "           7       0.55      0.46      0.50        50\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.69       480\n",
      "   macro avg       0.33      0.33      0.33       480\n",
      "weighted avg       0.66      0.69      0.67       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yRed_test, yRed_train, XRed_test, XRed_train, rankingRed = compareClassifiers(XRed, yRed, d)\n",
    "defaultPrediction(RandomForestClassifier(), yRed_test, yRed_train, XRed_test, XRed_train)\n",
    "hyperparameterOptimization('Random Forest', param_grid, rankingRed, yRed_test, yRed_train, XRed_test, XRed_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.3) White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6614512471655328, 'Random Forest', 0.682312925170068, 0.5108603954315185), (0.6029478458049886, 'KNearest Neighbors (1)', 0.6217687074829932, 0.05718321800231933), (0.5849433106575964, 'Decision Tree', 0.6095238095238096, 0.018873055775960285), (0.5534240362811791, 'SVM rbf', 0.5741496598639456, 0.6323601086934407), (0.5505215419501134, 'Multi-layer Perceptron Classifier', 0.5619047619047619, 9.040035645167032), (0.5258503401360545, 'Logistic Regression', 0.5401360544217687, 0.2921169281005859), (0.4723356009070295, 'SGD Classifier', 0.4993197278911565, 0.05157993634541829), (0.45446712018140584, 'Gaussian Naive Bayes', 0.47551020408163264, 0.0025489012400309245)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.661 bestScore: 0.682 averageTime: 0.510 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.602 bestScore: 0.621 averageTime: 0.057 s\n",
      "3 ) Decision Tree                      averageScore: 0.584 bestScore: 0.609 averageTime: 0.018 s\n",
      "4 ) SVM rbf                            averageScore: 0.553 bestScore: 0.574 averageTime: 0.632 s\n",
      "5 ) Multi-layer Perceptron Classifier  averageScore: 0.550 bestScore: 0.561 averageTime: 9.040 s\n",
      "6 ) Logistic Regression                averageScore: 0.525 bestScore: 0.540 averageTime: 0.292 s\n",
      "7 ) SGD Classifier                     averageScore: 0.472 bestScore: 0.499 averageTime: 0.051 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.454 bestScore: 0.475 averageTime: 0.002 s\n",
      "accuracy with standard parameters: 0.6761904761904762\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "GridSearchCV - Accuracy: 0.678912 - Time: 61.06 seconds\n",
      "Previous best Accuracy:  0.682312925170068\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1470 points : 472 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   4   3   0   0]\n",
      " [  0   7  29  16   0   0]\n",
      " [  0   1 323 114   8   0]\n",
      " [  0   0  91 511  44   0]\n",
      " [  0   0   5 117 139   2]\n",
      " [  0   0   0  24  14  18]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.88      0.13      0.23        52\n",
      "           5       0.71      0.72      0.72       446\n",
      "           6       0.65      0.79      0.71       646\n",
      "           7       0.68      0.53      0.59       263\n",
      "           8       0.90      0.32      0.47        56\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.64      0.42      0.46      1470\n",
      "weighted avg       0.69      0.68      0.66      1470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yWhite_test, yWhite_train, XWhite_test, XWhite_train, rankingWhite = compareClassifiers(XWhite, yWhite, d)\n",
    "defaultPrediction(RandomForestClassifier(), yWhite_test, yWhite_train, XWhite_test, XWhite_train)\n",
    "hyperparameterOptimization('Random Forest', param_grid, rankingWhite, yWhite_test, yWhite_train, XWhite_test, XWhite_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2) KNearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = param_grid = {'n_neighbors': [1,2,5,10,25,50,75,100,125],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'p': [1, 2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.1) Both Wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with standard parameters: 0.6128205128205129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 75, 'p': 1, 'weights': 'distance'}\n",
      "GridSearchCV - Accuracy: 0.665128 - Time: 7.76 seconds\n",
      "Previous best Accuracy:  0.6287179487179487\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1950 points : 653 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   6   1   0   0   0]\n",
      " [  0   5  38  22   0   0   0]\n",
      " [  0   0 438 200   3   0   0]\n",
      " [  0   0 139 676  44   0   0]\n",
      " [  0   0   6 165 155   0   0]\n",
      " [  0   0   1  15  11  23   0]\n",
      " [  0   0   0   2   0   0   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       1.00      0.08      0.14        65\n",
      "           5       0.70      0.68      0.69       641\n",
      "           6       0.63      0.79      0.70       859\n",
      "           7       0.73      0.48      0.58       326\n",
      "           8       1.00      0.46      0.63        50\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67      1950\n",
      "   macro avg       0.58      0.35      0.39      1950\n",
      "weighted avg       0.69      0.67      0.65      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultPrediction(KNeighborsClassifier(n_neighbors=NN), y_test, y_train, X_test, X_train)\n",
    "hyperparameterOptimization('KNearest Neighbors (1)', param_grid, rankingBoth, y_test, y_train, X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2) Red Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with standard parameters: 0.5833333333333334\n",
      "{'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "GridSearchCV - Accuracy: 0.672917 - Time: 2.03 seconds\n",
      "Previous best Accuracy:  0.675\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 480 points : 157 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   0]\n",
      " [  0   0  10   2   0   0]\n",
      " [  0   0 157  39   0   0]\n",
      " [  0   0  52 142   4   0]\n",
      " [  0   0   4  40  23   0]\n",
      " [  0   0   0   3   2   1]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.70      0.80      0.75       196\n",
      "           6       0.63      0.72      0.67       198\n",
      "           7       0.79      0.34      0.48        67\n",
      "           8       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.67       480\n",
      "   macro avg       0.52      0.34      0.36       480\n",
      "weighted avg       0.67      0.67      0.65       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultPrediction(KNeighborsClassifier(n_neighbors=NN), yRed_test, yRed_train, XRed_test, XRed_train)\n",
    "hyperparameterOptimization('KNearest Neighbors (1)', param_grid, rankingRed, yRed_test, yRed_train, XRed_test, XRed_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.3) White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with standard parameters: 0.6129251700680272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 50, 'p': 1, 'weights': 'distance'}\n",
      "GridSearchCV - Accuracy: 0.646939 - Time: 7.20 seconds\n",
      "Previous best Accuracy:  0.6312925170068027\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1470 points : 519 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   4   6   0   0   0]\n",
      " [  0   7  22  16   0   0   0]\n",
      " [  0   0 291 154   4   0   0]\n",
      " [  0   0  85 517  46   0   0]\n",
      " [  0   0   4 144 124   0   0]\n",
      " [  0   0   0  21  11  12   0]\n",
      " [  0   0   0   2   0   0   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       1.00      0.16      0.27        45\n",
      "           5       0.72      0.65      0.68       449\n",
      "           6       0.60      0.80      0.69       648\n",
      "           7       0.67      0.46      0.54       272\n",
      "           8       1.00      0.27      0.43        44\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.57      0.33      0.37      1470\n",
      "weighted avg       0.67      0.65      0.63      1470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultPrediction(KNeighborsClassifier(n_neighbors=NN), yWhite_test, yWhite_train, XWhite_test, XWhite_train)\n",
    "hyperparameterOptimization('KNearest Neighbors (1)', param_grid, rankingWhite, yWhite_test, yWhite_train, XWhite_test, XWhite_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth': [10, 50, 100, None],\n",
    "              'max_features' : ['auto', 'sqrt', 'log2', None],\n",
    "              'splitter' : ['best', 'random'],\n",
    "              'min_samples_leaf': [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.1) Both Wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6594871794871795, 'Random Forest', 0.6753846153846154, 0.6388326327006022), (0.599931623931624, 'KNearest Neighbors (1)', 0.6107692307692307, 0.062436215082804364), (0.5875897435897437, 'Decision Tree', 0.6087179487179487, 0.018895578384399415), (0.5561367521367521, 'Multi-layer Perceptron Classifier', 0.5738461538461539, 8.919428253173828), (0.5523760683760683, 'SVM rbf', 0.5753846153846154, 1.000402530034383), (0.5395897435897437, 'Logistic Regression', 0.5502564102564103, 0.31969141960144043), (0.49750427350427345, 'SGD Classifier', 0.5235897435897436, 0.05209256807963054), (0.48242735042735047, 'Gaussian Naive Bayes', 0.49948717948717947, 0.0026713848114013673)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.659 bestScore: 0.675 averageTime: 0.638 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.599 bestScore: 0.610 averageTime: 0.062 s\n",
      "3 ) Decision Tree                      averageScore: 0.587 bestScore: 0.608 averageTime: 0.018 s\n",
      "4 ) Multi-layer Perceptron Classifier  averageScore: 0.556 bestScore: 0.573 averageTime: 8.919 s\n",
      "5 ) SVM rbf                            averageScore: 0.552 bestScore: 0.575 averageTime: 1.000 s\n",
      "6 ) Logistic Regression                averageScore: 0.539 bestScore: 0.550 averageTime: 0.319 s\n",
      "7 ) SGD Classifier                     averageScore: 0.497 bestScore: 0.523 averageTime: 0.052 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.482 bestScore: 0.499 averageTime: 0.002 s\n",
      "accuracy with standard parameters: 0.5733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'splitter': 'best'}\n",
      "GridSearchCV - Accuracy: 0.578974 - Time: 6.93 seconds\n",
      "Previous best Accuracy:  0.6087179487179487\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1950 points : 821 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   1   6   0   1   0   0]\n",
      " [  1  11  30  28   7   0   0]\n",
      " [  4  17 394 152  44  10   0]\n",
      " [  5  13 183 520 118  20   0]\n",
      " [  0   5  23 109 178  13   1]\n",
      " [  0   0   0  22   7  26   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.23      0.14      0.18        77\n",
      "           5       0.62      0.63      0.63       621\n",
      "           6       0.62      0.61      0.62       859\n",
      "           7       0.50      0.54      0.52       329\n",
      "           8       0.38      0.47      0.42        55\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58      1950\n",
      "   macro avg       0.34      0.34      0.34      1950\n",
      "weighted avg       0.58      0.58      0.58      1950\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_train, X_test, X_train, rankingBoth = compareClassifiers(X, y, d)\n",
    "defaultPrediction(DecisionTreeClassifier(), y_test, y_train, X_test, X_train)\n",
    "hyperparameterOptimization('Decision Tree', param_grid, rankingBoth, y_test, y_train, X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.2) Red Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6734722222222221, 'Random Forest', 0.6958333333333333, 0.2597455660502116), (0.6187500000000001, 'KNearest Neighbors (1)', 0.6458333333333334, 0.023427947362263998), (0.6091666666666666, 'SVM rbf', 0.6375, 0.08624003728230795), (0.6024999999999999, 'Multi-layer Perceptron Classifier', 0.6333333333333333, 4.6421897411346436), (0.5898611111111111, 'Logistic Regression', 0.6166666666666667, 0.06326686541239421), (0.58875, 'Decision Tree', 0.6270833333333333, 0.005301268895467123), (0.5681944444444443, 'Gaussian Naive Bayes', 0.6208333333333333, 0.0019516785939534505), (0.5206944444444443, 'SGD Classifier', 0.59375, 0.016022364298502605)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.673 bestScore: 0.695 averageTime: 0.259 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.618 bestScore: 0.645 averageTime: 0.023 s\n",
      "3 ) SVM rbf                            averageScore: 0.609 bestScore: 0.637 averageTime: 0.086 s\n",
      "4 ) Multi-layer Perceptron Classifier  averageScore: 0.602 bestScore: 0.633 averageTime: 4.642 s\n",
      "5 ) Logistic Regression                averageScore: 0.589 bestScore: 0.616 averageTime: 0.063 s\n",
      "6 ) Decision Tree                      averageScore: 0.588 bestScore: 0.627 averageTime: 0.005 s\n",
      "7 ) Gaussian Naive Bayes               averageScore: 0.568 bestScore: 0.620 averageTime: 0.001 s\n",
      "8 ) SGD Classifier                     averageScore: 0.520 bestScore: 0.593 averageTime: 0.016 s\n",
      "accuracy with standard parameters: 0.59375\n",
      "{'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
      "GridSearchCV - Accuracy: 0.639583 - Time: 2.45 seconds\n",
      "Previous best Accuracy:  0.6270833333333333\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 480 points : 173 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   1   0   0   0   0]\n",
      " [  0   0   4   7   3   0]\n",
      " [  1   5 143  45   5   0]\n",
      " [  1   3  37 128  26   2]\n",
      " [  0   1   4  16  36   4]\n",
      " [  0   0   0   5   3   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.76      0.72      0.74       199\n",
      "           6       0.64      0.65      0.64       197\n",
      "           7       0.49      0.59      0.54        61\n",
      "           8       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.64       480\n",
      "   macro avg       0.32      0.33      0.32       480\n",
      "weighted avg       0.64      0.64      0.64       480\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yRed_test, yRed_train, XRed_test, XRed_train, rankingRed = compareClassifiers(XRed, yRed, d)\n",
    "defaultPrediction(DecisionTreeClassifier(), yRed_test, yRed_train, XRed_test, XRed_train)\n",
    "hyperparameterOptimization('Decision Tree', param_grid, rankingRed, yRed_test, yRed_train, XRed_test, XRed_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3.3) White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6680725623582766, 'Random Forest', 0.6836734693877551, 0.4857369581858317), (0.6085260770975057, 'KNearest Neighbors (1)', 0.6319727891156462, 0.05617793401082357), (0.5835374149659864, 'Decision Tree', 0.5993197278911565, 0.018264261881510417), (0.5570521541950113, 'SVM rbf', 0.5687074829931973, 0.6115099430084229), (0.5554195011337869, 'Multi-layer Perceptron Classifier', 0.5639455782312925, 8.597955703735352), (0.5299319727891156, 'Logistic Regression', 0.5544217687074829, 0.28619109789530434), (0.47256235827664395, 'SGD Classifier', 0.5108843537414965, 0.047141472498575844), (0.4532426303854875, 'Gaussian Naive Bayes', 0.47959183673469385, 0.002485036849975586)]\n",
      "\n",
      "Classifiers from best to worst:\n",
      "1 ) Random Forest                      averageScore: 0.668 bestScore: 0.683 averageTime: 0.485 s\n",
      "2 ) KNearest Neighbors (1)             averageScore: 0.608 bestScore: 0.631 averageTime: 0.056 s\n",
      "3 ) Decision Tree                      averageScore: 0.583 bestScore: 0.599 averageTime: 0.018 s\n",
      "4 ) SVM rbf                            averageScore: 0.557 bestScore: 0.568 averageTime: 0.611 s\n",
      "5 ) Multi-layer Perceptron Classifier  averageScore: 0.555 bestScore: 0.563 averageTime: 8.597 s\n",
      "6 ) Logistic Regression                averageScore: 0.529 bestScore: 0.554 averageTime: 0.286 s\n",
      "7 ) SGD Classifier                     averageScore: 0.472 bestScore: 0.510 averageTime: 0.047 s\n",
      "8 ) Gaussian Naive Bayes               averageScore: 0.453 bestScore: 0.479 averageTime: 0.002 s\n",
      "accuracy with standard parameters: 0.5816326530612245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'splitter': 'best'}\n",
      "GridSearchCV - Accuracy: 0.583673 - Time: 6.66 seconds\n",
      "Previous best Accuracy:  0.5993197278911565\n",
      "\n",
      "\n",
      "Additional statistics for prediction using best parameters:\n",
      "\n",
      "Number of mislabeled points out of a total 1470 points : 612 \n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   1   0   0   0]\n",
      " [  1  10  16  17   4   2   0]\n",
      " [  2  17 276 129  19   3   0]\n",
      " [  1  12 141 404  82  20   0]\n",
      " [  0   3  22  80 142   8   1]\n",
      " [  1   0   2  12  11  26   0]\n",
      " [  0   0   1   1   0   2   0]]\n",
      "Classsification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.24      0.20      0.22        50\n",
      "           5       0.60      0.62      0.61       446\n",
      "           6       0.63      0.61      0.62       660\n",
      "           7       0.55      0.55      0.55       256\n",
      "           8       0.43      0.50      0.46        52\n",
      "           9       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.35      0.36      0.35      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yWhite_test, yWhite_train, XWhite_test, XWhite_train, rankingWhite = compareClassifiers(XWhite, yWhite, d)\n",
    "defaultPrediction(DecisionTreeClassifier(), yWhite_test, yWhite_train, XWhite_test, XWhite_train)\n",
    "hyperparameterOptimization('Decision Tree', param_grid, rankingWhite, yWhite_test, yWhite_train, XWhite_test, XWhite_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Compare with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldComp(X, y):\n",
    "    # prepare configuration for cross validation test harness\n",
    "    seed = 7\n",
    "    # prepare models\n",
    "    models = []\n",
    "\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=1)))\n",
    "    #models.append(('NBayes', GaussianNB()))\n",
    "    models.append(('RandomForest', RandomForestClassifier()))\n",
    "    models.append(('DTree', DecisionTreeClassifier()))\n",
    "    #models.append(('SVM', SVC()))\n",
    "    #models.append(('LRegression', LogisticRegression(max_iter=200)))\n",
    "\n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'accuracy'\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10)\n",
    "        cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "    return(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.439886 (0.024676)\n",
      "RandomForest: 0.534249 (0.026245)\n",
      "DTree: 0.421734 (0.031336)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, names = kFoldComp(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.494646 (0.059566)\n",
      "RandomForest: 0.560967 (0.061727)\n",
      "DTree: 0.475881 (0.044016)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYjklEQVR4nO3dfZRddX3v8feHyENbecg0oyIEghqsKBrruVihKr0tkNou0FoRy62Eq1LvkuKqWIu9XgmhtcK9eq2F1lIX4kMpD97KGq5tEVFEeTITDWDCRUOAkogSSHiSx4TP/WP/BjfTmeRM5sycmV8+r7XOmrN/++F89z4zn7PPb+/ZW7aJiIh67dTvAiIiYmol6CMiKpegj4ioXII+IqJyCfqIiMol6CMiKpegjwmRdIGkv5iiZR8v6WtbGX+4pHVT8dqznaQ/l/TZftcRM1OCPsYk6WpJmyTtOl2vafsfbR/ZqsGSXjJdr6/GKZJ+IOlnktZJulTSwdNVw/ay/THb7+53HTEzJejjP5C0AHg9YODoaXrN50zH62zDXwPvB04BBoADgcuA3+ljTds0Q7ZdzGAJ+hjLO4EbgAuAE7Y2oaQPSbpH0o8lvbu9Fy5pT0lfkLRB0l2SPiJppzJuiaRrJf1vSfcDS0vbd8r4a8pL3CTpEUlvb73mqZLuLa97Yqv9Akl/K+lfyzzXSnqBpE+Vbyf/T9Krx1mPhcD7gHfY/obtJ2w/Wr5lfHyC6/OApLWSDi3td5d6TxhV62ckXSnpYUnfkrR/a/xfl/kekrRC0utb45ZK+rKkL0l6CFhS2r5Uxu9Wxt1falku6fll3AslDUnaKGmNpPeMWu4lZR0flrRKUmdr73/MDgn6GMs7gX8sj6NGQmI0SYuBDwC/BbwEOHzUJH8D7Am8CHhjWe6JrfGvBdYCzwf+sj2j7TeUp6+y/VzbF5fhF5Rl7gO8CzhX0tzWrMcCHwHmAU8A1wPfK8NfBj45zjr/JrDO9nfHGd/t+twM/DJwIXAR8J9ots1/Ac6R9NzW9McDZ5baVtJs7xHLgUU03ywuBC6VtFtr/DFlffYaNR80H857AvNLLe8FHivjLgLWAS8Efh/4mKT/3Jr36DLNXsAQcM74myNmiwR9PIukXwf2By6xvQK4HfiDcSY/Fvic7VW2HwWWtpYzBzgO+LDth23fCXwC+MPW/D+2/Te2N9t+jO48BSyz/ZTtfwEeAV7aGv8V2ytsPw58BXjc9hdsbwEuBsbco6cJxHvGe9Eu1+cO259rvdb8UusTtr8GPEkT+iO+avsa208A/x14naT5ALa/ZPv+sm0+Aew6aj2vt32Z7afH2HZPlfV5ie0tZXs8VJZ9GPBnth+3vRL4LM0H1ojv2P6Xsg5fBF413jaJ2SNBH6OdAHzN9n1l+ELG7755IXB3a7j9fB6wM3BXq+0umj3xsabv1v22N7eGHwXae8k/bT1/bIzh9rTPWi6w91Zet5v1Gf1a2N7a6z+z/rYfATbSbFMkfVDSrZIelPQAzR76vLHmHcMXgSuAi0qX2tmSdi7L3mj74a2sw09azx8FdssxgNkvQR/PkPQLNHvpb5T0E0k/Af4EeJWksfbs7gH2bQ3Pbz2/j2bPcv9W237A+tbwTLp06lXAvlvpk+5mfSbqme1VunQGgB+X/vgP0bwXc23vBTwIqDXvuNuufNs5w/ZBwKHA79Lstf8YGJC0ew/XIWaBBH20vRnYAhxE0z+8CHgZ8G2e/fV+xCXAiZJeJukXgf8xMqJ89b8E+EtJu5cDjR8AvjSBen5K0x8+5Wz/CPhb4J/UnK+/SzmoeZyk03q0PqO9SdKvS9qFpq/+Btt3A7sDm4ENwHMkfRTYo9uFSvoNSQeX7qaHaD6gni7Lvg74q7Jur6Q5zjGZdYhZIEEfbSfQ9Ln/u+2fjDxoDsgdP/orvO1/BT4NfBNYQ3OmDjQHQQH+GPgZzQHX79B0A50/gXqWAp8vZ44cu53rNBGn0KzrucADNMcn3gJcXsZPdn1GuxA4nabL5jU0B2yh6Xb5N+CHNF0rjzOxbq4X0ByofQi4FfgWTXcOwDuABTR7918BTrf99UmsQ8wCyo1HolckvQz4AbDrqH70GEXSBTRn+Xyk37VE/bJHH5Mi6S2Sdi2nOJ4FXJ6Qj5hZEvQxWX8E3EvTzbEF+G/9LSciRkvXTURE5bJHHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlZtzd3efNm+cFCxb0u4yIiFllxYoV99keHGvcjAv6BQsWMDw83O8yIiJmFUl3jTcuXTcREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlZtw/TEX0i6SeLMd2T5YT0SsJ+oiim4CWlCCPWSddNxERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlesq6CUtlnSbpDWSThtnmmMlrZa0StKFrfYtklaWx1CvCo+IiO5s81aCkuYA5wJHAOuA5ZKGbK9uTbMQ+DBwmO1Nkp7XWsRjthf1tuyIiOhWN3v0hwBrbK+1/SRwEXDMqGneA5xrexOA7Xt7W2ZERGyvboJ+H+Du1vC60tZ2IHCgpGsl3SBpcWvcbpKGS/ubJ1duRERM1Da7biawnIXA4cC+wDWSDrb9ALC/7fWSXgR8Q9Ittm9vzyzpJOAkgP32269HJUVEBHS3R78emN8a3re0ta0Dhmw/ZfsO4Ic0wY/t9eXnWuBq4NWjX8D2ebY7tjuDg4MTXomIiBhfN0G/HFgo6QBJuwDHAaPPnrmMZm8eSfNounLWSporaddW+2HAaiIiYtpss+vG9mZJJwNXAHOA822vkrQMGLY9VMYdKWk1sAX4U9v3SzoU+HtJT9N8qHy8fbZORERMPdnudw3P0ul0PDw83O8yIsYkiZn2NxMBIGmF7c5Y4/KfsRERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfEVG5BH1EROUS9BERlUvQR0RULkEfO4yBgQEkTeoBTHoZAwMDfd4SsaPpKuglLZZ0m6Q1kk4bZ5pjJa2WtErSha32EyT9qDxO6FXhERO1adMmbPf9sWnTpn5vitjBPGdbE0iaA5wLHAGsA5ZLGrK9ujXNQuDDwGG2N0l6XmkfAE4HOoCBFWXe/KZHREyTbvboDwHW2F5r+0ngIuCYUdO8Bzh3JMBt31vajwKutL2xjLsSWNyb0iMiohvdBP0+wN2t4XWlre1A4EBJ10q6QdLiCcwbERFTaJtdNxNYzkLgcGBf4BpJB3c7s6STgJMA9ttvvx6VFBER0N0e/Xpgfmt439LWtg4Ysv2U7TuAH9IEfzfzYvs82x3bncHBwYnUHxER29BN0C8HFko6QNIuwHHA0KhpLqPZm0fSPJqunLXAFcCRkuZKmgscWdoiImKabLPrxvZmSSfTBPQc4HzbqyQtA4ZtD/HzQF8NbAH+1Pb9AJLOpPmwAFhme+NUrEhERIxNtvtdw7N0Oh0PDw/3u4yokCRmwu/7TKkj6iJphe3OWOPyn7EREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQREZXr1R2mopDUk+Xk6oYR0SsJ+h7bVkDnErURMd3SdRMRUbkEfURE5RL0ERGVS9BHRFQuQR8RUbkEfURE5RL0ERGVS9BHRFQuQR8RUbkEfURE5RL0ERGVy7VuIqIKuaDg+Lrao5e0WNJtktZIOm2M8UskbZC0sjze3Rq3pdU+1MviIyJG2N7qo5tpagx56GKPXtIc4FzgCGAdsFzSkO3Voya92PbJYyziMduLJl1pRERsl2726A8B1thea/tJ4CLgmKktKyIieqWboN8HuLs1vK60jfZWSTdL+rKk+a323SQNS7pB0psnUWtERGyHXp11czmwwPYrgSuBz7fG7W+7A/wB8ClJLx49s6STyofB8IYNG3pU0tQYGBhA0nY/gEnNL4mBgYE+b4WImE26OetmPdDeQ9+3tD3D9v2twc8CZ7fGrS8/10q6Gng1cPuo+c8DzgPodDoz+mjIpk2b+n7ApldnF+xofPoesHTPfpfR1BExjboJ+uXAQkkH0AT8cTR758+QtLfte8rg0cCtpX0u8KjtJyTNAw6j9SEQMZ10xkN9/5CGcjvJpf2uInYk2wx625slnQxcAcwBzre9StIyYNj2EHCKpKOBzcBGYEmZ/WXA30t6mqab6ONjnK0TERFTSDNhD6et0+l4eHi432WMaybc3Hsm1DAbzZTtNlPq2NHUvt0lrSjHQ/+DXAIhIqJyCfqIiMol6CMiKpegj4ioXII+IqJyCfqIiMol6CMiKpegj4ioXII+IqJyCfqIiMol6CMiKpegj4ioXII+IqJy3VyPPqIaM+GmLXPnzu13CbGDSdDHDqMXl6it/VK3Uad03UREVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQREZVL0EdEVC5BHxFRuQR9RETlEvQRMSsMDAwgabsfwKTml8TAwECft8L26SroJS2WdJukNZJOG2P8EkkbJK0sj3e3xp0g6UflcUIvi4+IHcemTZuw3dfHpk2b+r0Ztss2r14paQ5wLnAEsA5YLmnI9upRk15s++RR8w4ApwMdwMCKMu/s3FoREbNQN3v0hwBrbK+1/SRwEXBMl8s/CrjS9sYS7lcCi7ev1IiI2B7dBP0+wN2t4XWlbbS3SrpZ0pclzZ/gvBERMUV6dTD2cmCB7VfS7LV/fiIzSzpJ0rCk4Q0bNvSopIiIgO6Cfj0wvzW8b2l7hu37bT9RBj8LvKbbecv859nu2O4MDg52W3tERHShm6BfDiyUdICkXYDjgKH2BJL2bg0eDdxanl8BHClprqS5wJGlLSIipsk2z7qxvVnSyTQBPQc43/YqScuAYdtDwCmSjgY2AxuBJWXejZLOpPmwAFhme+MUrEdERIxDM+1Gx51Ox8PDw/0uY1wz4ebQM6GGHVW2ff/MhG0/E2oYj6QVtjtjjct/xkZEVC5BHxFRuQR9RETlEvQREZXb5lk38Ww+fQ9Yumf/a4iI6FKCfoJ0xkN9P+ouCS/tawkRMYuk6yYionIJ+oiIyqXrJiJmhRwf234J+oiYFXJ8bPul6yYionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql2vdRBSSejJdv6/HEjFagj6iSEBHrdJ1ExFRuQR9RETlEvQREZVL0EdEVK6roJe0WNJtktZIOm0r071VkiV1yvACSY9JWlken+lV4RER0Z1tnnUjaQ5wLnAEsA5YLmnI9upR0+0OvB+4cdQibre9qDflRkTERHWzR38IsMb2WttPAhcBx4wx3ZnAWcDjPawvIiImqZug3we4uzW8rrQ9Q9KvAvNtf3WM+Q+Q9H1J35L0+rFeQNJJkoYlDW/YsKHb2iMioguTPhgraSfgk8CpY4y+B9jP9quBDwAXStpj9ES2z7Pdsd0ZHBycbEkREdHSTdCvB+a3hvctbSN2B14BXC3pTuDXgCFJHdtP2L4fwPYK4HbgwF4UHhER3ekm6JcDCyUdIGkX4DhgaGSk7Qdtz7O9wPYC4AbgaNvDkgbLwVwkvQhYCKzt+VpERMS4tnnWje3Nkk4GrgDmAOfbXiVpGTBse2grs78BWCbpKeBp4L22N/ai8IiI6I5m2oWcOp2Oh4eH+13GuCT1/eJXM6GGiOk2E37vZ0IN45G0wnZnrHG5euV26PZytlNl7ty5fX39iJhdEvQTNNlP85m8RxARdcq1biIiKpc9+oiYNdJtun0S9BExK6TbdPul6yYionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql6CPiKhcgj4ionIJ+oiIyiXoIyIql3vGRkQVurlxeDfT1Hhf2QR9RFShxoDulQR9j2WvIiJmmq766CUtlnSbpDWSTtvKdG+VZEmdVtuHy3y3STqqF0XPZLZ78oiI6JVt7tFLmgOcCxwBrAOWSxqyvXrUdLsD7wdubLUdBBwHvBx4IfB1SQfa3tK7VYiIiK3pZo/+EGCN7bW2nwQuAo4ZY7ozgbOAx1ttxwAX2X7C9h3AmrK8iIiYJt0E/T7A3a3hdaXtGZJ+FZhv+6sTnbfMf5KkYUnDGzZs6KrwiIjozqTPo5e0E/BJ4NTtXYbt82x3bHcGBwcnW1JERLR0c9bNemB+a3jf0jZid+AVwNXlbJIXAEOSju5i3oiImGLd7NEvBxZKOkDSLjQHV4dGRtp+0PY82wtsLwBuAI62PVymO07SrpIOABYC3+35WkRExLi2uUdve7Okk4ErgDnA+bZXSVoGDNse2sq8qyRdAqwGNgPvyxk3ERHTSzPtnO1Op+Ph4eF+lxERMatIWmG7M+a4mRb0kjYAd/W7jik0D7iv30XEdsv7N3vV/t7tb3vMs1lmXNDXTtLweJ+6MfPl/Zu9duT3LpcpjoioXII+IqJyCfrpd16/C4hJyfs3e+2w71366CMiKpc9+oiIyiXoe0TSI63nb5L0Q0n7S1oq6VFJzxtnWkv6RGv4g5KWTlvhs4CkLZJWSvqBpMsl7dWj5S6RdE6PlnWnpFtKnSslHdqL5Y7xOoskvWkqlj2btH4nVkm6SdKpknaSdFTrPXik3AdjpaQv9LvmfkrQ95ik3wQ+Dfy27ZH/B7iP8S/69gTwe5LmTUd9s9RjthfZfgWwEXhfvwsax2+UOhfZvq6bGSRN9C5vi4AdPuj5+e/Ey2nulfHbwOm2rxh5D4Bh4Pgy/M6RGcs9NnYoCfoekvQG4B+A37V9e2vU+cDbJQ2MMdtmmoNEfzINJdbgesqlriUdIul6Sd+XdJ2kl5b2JZL+WdK/SfqRpLNHZpZ0Yvm29V3gsFb7AknfkHSzpKsk7VfaL5D0d5JukLRW0uGSzpd0q6QLtlboNpb5GUk3AmdLenGpdYWkb0v6lTLd28q3mJskXVOuNbWM5ndppaS393LDzla27wVOAk6Wxr5PZ/nGdZak7wFvk3Rk+d35nqRLJT23TPcaSd8q78UVkvaexlWZOr269d2O/gCeotnbfOWo9qXAB4GPAmeUtkda4x8B9gDuBPYs0y7t9/rMpMfI9qK51tKlwOIyvAfwnPL8t4D/U54vAdaW7bkbzX9azwf2Bv4dGAR2Aa4FzinzXA6cUJ7/V+Cy8vwCmpvtiOZGOg8BB9PsJK0AFpXp7gRuAVYCN3axzP8LzCnDVwELy/PXAt8oz28B9inP92qt2zn9fk/6/Wj/DbXaHgCe3xq+Gui03p8PlefzgGuAXyrDf1b+PncGrgMGS/vbaa7t1ff1newjNwfvnadofkneRXNLxdE+DayU9L9Gj7D9UOlDPAV4bEqrnJ1+QdJKmj35W4ErS/uewOclLQRM84c64irbDwJIWg3sT/MHfrXtDaX9YuDAMv3rgN8rz78InN1a1uW2LekW4Ke2bynzrwIW0IQ7NF037X+x39oyL7W9pexJHgpc2toZ3bX8vBa4oFwY8J+3toGiKxeXn78GHARcW7b5LjTfFF9Kc8n1K0v7HOCe6S+z9xL0vfM0cCxwlaQ/t/2x9kjbD0i6kPH7lz8FfA/43JRWOTs9ZnuRpF+kuYrq+2g+OM8Evmn7LZIW0OzBjXii9XwLk/tdH1nW06OW+/Qklvuz8nMn4AE3fcrPYvu9kl4L/A6wQtJrtvO1qifpRTTv871bmWxkmwu40vY7Ri3jYGCV7ddNTZX9kz76HrL9KM0f5fGS3jXGJJ8E/ogxwsH2RuASmm8EMYayfU8BTi0HMffk5zeyWdLFIm4E3ijplyXtDLytNe46mnstABwPfLsHJW9zmbYfAu6Q9DYANV5Vnr/Y9o22PwpsoOl+epjmZj9RSBoEPkPTpdXNPwbdABwm6SVl/l+SdCBwGzAo6XWlfWdJL5+quqdTgr7HSmAvBj6i5i5b7XH3AV/h51/NR/sETfdCjMP294GbgXfQdIX8laTv0929Fe6hOWZyPU23yK2t0X8MnCjpZuAPGbv7baK6XebxwLsk3QSsojkWAPA/1Zyy+QOaD42bgG8CB+VgbNOdV7rPvg58DTijmxlL190S4J/Ke3M98Cu2nwR+HzirvBcrabrVZr38Z2xEROWyRx8RUbkEfURE5RL0ERGVS9BHRFQuQR8RUbkEfURE5RL0ERGVS9BHRFTu/wNP2gy4CISR3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsRed, namesRed = kFoldComp(XRed, yRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.454885 (0.033524)\n",
      "RandomForest: 0.530039 (0.041904)\n",
      "DTree: 0.419376 (0.031733)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsWhite, namesWhite = kFoldComp(XWhite, yWhite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax1 = fig.add_subplot(113)\n",
    "    ax1.title(\"Both Wines\")\n",
    "    plt.boxplot(results)\n",
    "    ax1.set_xticklabels(names)\n",
    "    ax2 = fig.add_subplot(213)\n",
    "    ax2.title(\"Red Wines\")\n",
    "    plt.boxplot(resultsRed)\n",
    "    ax2.set_xticklabels(names)\n",
    "    ax3 = fig.add_subplot(313)\n",
    "    ax3.title(\"White Wines\")\n",
    "    plt.boxplot(resultsRed)\n",
    "    ax3.set_xticklabels(names)\n",
    "    plt.show()\n",
    "    return(results, names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
