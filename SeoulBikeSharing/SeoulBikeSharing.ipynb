{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seoul Bike Sharing\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "**-Rented Bike count:**  - Count of bikes rented at each hour, continuous numeric value<br>\n",
    "**-Hour:** Hour of the day numeric value <br>\n",
    "**-Temperature:** in Celsius numeric value <br>\n",
    "**-Humidity:** in %, numeric value <br>\n",
    "**-Windspeed:** in m/s, numeric value<br>\n",
    "**-Visibility:** in 10m, numeric value<br>\n",
    "**-Dew point temperature:** in Celsius, numeric value<br>\n",
    "**-Solar radiation:** MJ/m2, numeric value<br>\n",
    "**-Rainfall:** in mm, numeric value<br>\n",
    "**-Snowfall:** in cm, numeric value<br>\n",
    "**-Seasons:** Winter, Spring, Summer, Autumn categorical value<br>\n",
    "**-Holiday:** Holiday/No holiday binary value<br>\n",
    "**-Functional Day:** NoFunc(Non Functional Hours), Fun(Functional hours) binary value<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../RegressionAlgorithms/')\n",
    "from knn import *\n",
    "import linearRegressionNumpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SeoulBikeData.csv', delimiter = ',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rented Bike Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Histogram of Rented Bike Count Distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "bins = np.arange(0, 3540, 100).tolist()\n",
    "data['Rented Bike Count'].hist(bins=bins)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Rented Bike Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rented Bike Count vs Season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Seasons'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Rented Bike Count vs Seasons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=data['Seasons'], y=data['Rented Bike Count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rented Bike Count vs Holiday**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Rented Bike Count vs Holiday*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "sns.boxplot(x=data['Holiday'], y=data['Rented Bike Count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Temperature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Rented Bike Count vs Temperature*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data.iloc[:,2], y=data['Rented Bike Count'], kind='reg') #'Temperature(Â°C)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Rainfall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Rented Bike Count vs Rainfall*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['Rainfall(mm)'], y=data['Rented Bike Count'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['Rainfall(mm)'] >= 20)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['Rainfall(mm)'], y=data['Rented Bike Count'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Rainfall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Wind Speed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(data=data, x=\"Wind speed (m/s)\", y=\"Rented Bike Count\", kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['Wind speed (m/s)'] >6)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(data=data, x=\"Wind speed (m/s)\", y=\"Rented Bike Count\", kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Snowfall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Snowfall*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data=data, x=\"Snowfall (cm)\", y=\"Rented Bike Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with snowy days*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snowy = data.loc[(data['Snowfall (cm)'] > 0)]\n",
    "#data_snowy = data.loc[(data['weather_main'] == \"Snow\")]\n",
    "data_snowy.index = np.arange(1, len(data_snowy) + 1)\n",
    "data_snowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(data=data_snowy, x=\"Snowfall (cm)\", y=\"Rented Bike Count\", kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Hour**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Hour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(data=data_snowy, x=\"Hour\", y=\"Rented Bike Count\", kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering on Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Day','Month','Year']] = data['Date'].str.extract('(\\d+)/(\\d+)/(\\d+)', expand=True)\n",
    "data = data.drop(['Date'], axis=1)\n",
    "data[['Day','Month','Year']] = data[['Day','Month','Year']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bike Count vs Year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "sns.boxplot(x=data['Year'], y=data['Rented Bike Count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bike Count vs Year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.boxplot(x=data['Month'], y=data['Rented Bike Count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Rented Bike Count vs Hour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.boxplot(x=data['Hour'], y=data['Rented Bike Count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess Binary Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(to_replace=['No Holiday', 'Holiday'], value=[0, 1])\n",
    "data = data.replace(to_replace=['No', 'Yes'], value=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess Non Ordinal Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"Seasons\"])\n",
    "data = data.drop(\"Seasons\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Rented Bike Count', axis=1)\n",
    "y = data['Rented Bike Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Split the data in attributes and class as well as training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Algorithms from Sklearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred1 = model.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred1, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred1))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred1))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = KNeighborsRegressor(n_neighbors=5).fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = DecisionTreeRegressor(random_state = 0).fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Seoul: Linear Regression Function (MSE):')    \n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'MSE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "    \n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "\n",
    "\n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('SeoulBikeSharing: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_scikit_prediction_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MSE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_our_prediction_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MSE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('SeoulBikeSharing_total_error_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MSE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('SeoulBikeSharing_relative_error_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Seoul: Linear Regression Function (MSE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n \\n Seoul: Linear Regression Function (MAE):')    \n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'MAE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "    \n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('SeoulBikeSharing: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_scikit_prediction_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MAE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_our_prediction_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MAE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('SeoulBikeSharing_total_error_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (MAE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('SeoulBikeSharing_relative_error_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Seoul: Linear Regression Function (MAE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Seoul: Linear Regression Function (RMSE):')\n",
    "\n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'RMSE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "\n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('SeoulBikeSharing: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_scikit_prediction_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (RMSE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Rented Bike Count')\n",
    "plt.savefig('SeoulBikeSharing_our_prediction_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (RMSE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('SeoulBikeSharing_total_error_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('SeoulBikeSharing: our prediction (RMSE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('SeoulBikeSharing_relative_error_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Seoul: Linear Regression Function (RMSE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "plt.subplots(figsize=(20,9))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature = corr.index[abs(corr['Rented Bike Count'])>0.3]\n",
    "plt.subplots(figsize=(12, 8))\n",
    "top_corr = data[top_feature].corr()\n",
    "sns.heatmap(top_corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr.sort_values(['Rented Bike Count'], ascending=False, inplace=True)\n",
    "corr['Rented Bike Count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary creation to apply the mathematical functions of the algorithm**\n",
    "\n",
    "Training Data Option:\n",
    "- 0: All Data (except the target)\n",
    "- 1: X_train/y_train (train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_option = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_option == 0:\n",
    "    training_data = data\n",
    "elif training_data_option == 1:\n",
    "    training_data = data[data.index.isin(X_train.index)]\n",
    "    test_data = data[data.index.isin(X_test.index)]\n",
    "    \n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_option == 0:\n",
    "    training_dictionary = training_data.to_dict('records')\n",
    "elif training_data_option == 1:\n",
    "    training_dictionary = training_data.to_dict('records')\n",
    "    test_dictionary = test_data.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecasting instances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1 # 1 = KNeighbors; 2 = RadiusNeighbors\n",
    "n_neighbours = 5\n",
    "distance_function = 1 # 1 = Euclidean Distance; 2 = Manhattan Distance\n",
    "radius = 0 # 0 indicates no radius\n",
    "label = 'Rented Bike Count'\n",
    "features = ['Temperature(ï¿½C)','Hour','Dew point temperature(ï¿½C)','Winter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(training_dictionary, label, features, mode, n_neighbours, distance_function, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution of the algorithm (forecasting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "if training_data_option == 0:\n",
    "    for x in y_test.index:\n",
    "        #print(x)\n",
    "        target = training_dictionary[x-1]\n",
    "        #print(target)\n",
    "        result = knn.run(target)\n",
    "        #print(result)\n",
    "        results.append(result)\n",
    "elif training_data_option == 1:\n",
    "    for x in y_test.index:\n",
    "        #print(x)\n",
    "        target = test_dictionary[x]\n",
    "        #print(target)\n",
    "        result = knn.run(target)\n",
    "        #print(result)\n",
    "        results.append(result)\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(results,index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, predictions))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
