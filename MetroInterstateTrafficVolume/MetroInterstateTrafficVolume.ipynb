{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metro Interstate Traffic Volume\n",
    "\n",
    "**Data Set Information:**\n",
    "\n",
    "Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.\n",
    "\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "**- holiday:** Categorical US National holidays plus regional holiday, Minnesota State Fair;<br>\n",
    "**- temp:** Numeric Average temp in kelvin;<br>\n",
    "**- rain_1h:** Numeric Amount in mm of rain that occurred in the hour;<br>\n",
    "**- snow_1h:** Numeric Amount in mm of snow that occurred in the hour;<br>\n",
    "**- clouds_all:** Numeric Percentage of cloud cover;<br>\n",
    "**- weather_main:** Categorical Short textual description of the current weather;<br>\n",
    "**- weather_description:** Categorical Longer textual description of the current weather;<br>\n",
    "**- date_time:** DateTime Hour of the data collected in local CST time;<br>\n",
    "**- traffic_volume:** Numeric Hourly I-94 ATR 301 reported westbound traffic volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../RegressionAlgorithms/')\n",
    "from knn import *\n",
    "import linearRegressionNumpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MetroInterstateTrafficVolume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Histogram of Traffic Volume distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "bins = np.arange(0, 7500, 250).tolist()\n",
    "data['traffic_volume'].hist(bins=bins)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('traffic_volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Holiday**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check holidays included in the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holiday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Holiday distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['holiday'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with the holidays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holidays = data.loc[(data['holiday'] != 'None')]\n",
    "data_holidays.index = np.arange(1, len(data_holidays) + 1)\n",
    "data_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Holiday distribution (only holidays included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data_holidays['holiday'], y=data_holidays['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Temperature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Temperature distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['temp'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['temp'] <= 50)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Temperature distribution (without outliers)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['temp'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Rain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['rain_1h'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['rain_1h'] >= 1000)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution (without outliers)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['rain_1h'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with rainy days*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rainy = data.loc[(data['rain_1h'] > 0)]\n",
    "#data_rainy = data.loc[(data['weather_main'] == \"Rain\")]\n",
    "data_rainy.index = np.arange(1, len(data_rainy) + 1)\n",
    "data_rainy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution (only rainy days included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data_rainy['rain_1h'], y=data_rainy['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Snow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Snow distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['snow_1h'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with snowy days*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snowy = data.loc[(data['snow_1h'] > 0)]\n",
    "#data_snowy = data.loc[(data['weather_main'] == \"Snow\")]\n",
    "data_snowy.index = np.arange(1, len(data_snowy) + 1)\n",
    "data_snowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Snow distribution (only snowy days included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data_snowy['snow_1h'], y=data_snowy['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Cloud cover**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Cloud cover distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['clouds_all'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Current weather**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Current weather distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['weather_main'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Date time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Separation of the date elements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['year','month','day','hour','minutes','seconds']] = data['date_time'].str.extract(r'(\\d+)-(\\d+)-(\\d+)\\s*(\\d+):(\\d+):(\\d+)', expand=True)\n",
    "data = data.drop(['date_time'], axis=1)\n",
    "data[['year','month','day','hour','minutes','seconds']] = data[['year','month','day','hour','minutes','seconds']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset with new labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['year'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Month*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['month'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Hour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['hour'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drop minutes and second columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['minutes', 'seconds'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess Non Ordinal Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"weather_main\"])\n",
    "data = data.drop(\"weather_main\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"weather_description\"])\n",
    "data = data.drop(\"weather_description\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"holiday\"])\n",
    "data = data.drop(\"holiday\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('traffic_volume', axis=1)\n",
    "y = data['traffic_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Split the data in attributes and class as well as training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Algorithms from Sklearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred1 = model.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred1, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred1))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred1))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = KNeighborsRegressor(n_neighbors=3).fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = DecisionTreeRegressor(random_state = 0).fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cross validation score: ', cross_val_score(model, X_test, y_pred, cv=10))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Metro: Linear Regression Function (MSE):')  \n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'MSE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "\n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Traffic Volume (cars/h)')\n",
    "plt.savefig('MetroInterstateTrafficVolume_scikit_prediction_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MSE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Traffic Volume (cars/h)')\n",
    "plt.savefig('MetroInterstateTrafficVolume_our_prediction_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MSE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_total_error_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MSE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_relative_error_MSE.jpeg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Metro: Linear Regression Function (MSE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Metro: Linear Regression Function (MAE):')\n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'MAE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "\n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.savefig('MetroInterstateTrafficVolume_scikit_prediction_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MAE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.savefig('MetroInterstateTrafficVolume_our_prediction_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MAE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_total_error_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (MAE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_relative_error_MAE.jpeg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Metro: Linear Regression Function (MAE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Metro: Linear Regression Function (RMSE):')\n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare |    time/s')\n",
    "for convergenceCriterion in convCritList:\n",
    "    start = time.time()\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'RMSE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    end = time.time()\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13.0E} | {:19}| {:21}| {:11}| {:8.4f}| {:10.5f}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        r2_score(y_test, yPred2),\n",
    "                                        end-start))\n",
    "\n",
    "print('\\nFinal weigths for smallest epsilon = {:2.0E}:'.format(convCritList[-1]))\n",
    "print('weights = ', weights, '\\n')\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: scikit prediction')\n",
    "plt.plot(y_pred1)\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.savefig('MetroInterstateTrafficVolume_scikit_prediction_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (RMSE)')\n",
    "plt.plot(yPred2)\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.savefig('MetroInterstateTrafficVolume_our_prediction_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (RMSE) vs. scikit prediction')\n",
    "plt.plot(yPred2-y_pred1)\n",
    "plt.ylabel('total error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_total_error_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.title('MetroInterstateTrafficVolume: our prediction (RMSE) vs. scikit prediction')\n",
    "plt.plot((yPred2-y_pred1)/y_pred1)\n",
    "plt.ylabel('relative error')\n",
    "plt.savefig('MetroInterstateTrafficVolume_relative_error_RMSE.jpeg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Metro: Linear Regression Function (RMSE):')\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, yPred2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, yPred2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, yPred2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, yPred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary creation to apply the mathematical functions of the algorithm**\n",
    "\n",
    "Training Data Option:\n",
    "- 0: All Data (except the target)\n",
    "- 1: X_train/y_train (train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_option = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_option == 0:\n",
    "    training_data = data\n",
    "elif training_data_option == 1:\n",
    "    training_data = data[data.index.isin(X_train.index)]\n",
    "    test_data = data[data.index.isin(X_test.index)]\n",
    "    \n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_option == 0:\n",
    "    training_dictionary = training_data.to_dict('records')\n",
    "elif training_data_option == 1:\n",
    "    training_dictionary = training_data.to_dict('records')\n",
    "    test_dictionary = test_data.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecasting instances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1 # 1 = KNeighbors; 2 = RadiusNeighbors\n",
    "n_neighbours = 5\n",
    "distance_function = 1 # 1 = Euclidean Distance; 2 = Manhattan Distance\n",
    "radius = 0 # 0 indicates no radius\n",
    "label = 'traffic_volume'\n",
    "features = ['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(training_dictionary, label, features, mode, n_neighbours, distance_function, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution of the algorithm (forecasting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "if training_data_option == 0:\n",
    "    for x in y_test.index:\n",
    "        #print(x)\n",
    "        target = training_dictionary[x-1]\n",
    "        #print(target)\n",
    "        result = knn.run(target)\n",
    "        #print(result)\n",
    "        results.append(result)\n",
    "elif training_data_option == 1:\n",
    "    for x in y_test.index:\n",
    "        #print(x)\n",
    "        target = test_dictionary[x]\n",
    "        #print(target)\n",
    "        result = knn.run(target)\n",
    "        #print(result)\n",
    "        results.append(result)\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(results,index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, predictions))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print(\"Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
