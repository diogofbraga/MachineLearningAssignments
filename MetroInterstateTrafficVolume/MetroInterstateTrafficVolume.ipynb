{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metro Interstate Traffic Volume\n",
    "\n",
    "**Data Set Information:**\n",
    "\n",
    "Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.\n",
    "\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "**- holiday:** Categorical US National holidays plus regional holiday, Minnesota State Fair;<br>\n",
    "**- temp:** Numeric Average temp in kelvin;<br>\n",
    "**- rain_1h:** Numeric Amount in mm of rain that occurred in the hour;<br>\n",
    "**- snow_1h:** Numeric Amount in mm of snow that occurred in the hour;<br>\n",
    "**- clouds_all:** Numeric Percentage of cloud cover;<br>\n",
    "**- weather_main:** Categorical Short textual description of the current weather;<br>\n",
    "**- weather_description:** Categorical Longer textual description of the current weather;<br>\n",
    "**- date_time:** DateTime Hour of the data collected in local CST time;<br>\n",
    "**- traffic_volume:** Numeric Hourly I-94 ATR 301 reported westbound traffic volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../RegressionAlgorithms/')\n",
    "import linearRegression\n",
    "from knn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MetroInterstateTrafficVolume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Histogram of Traffic Volume distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,5))\n",
    "sns.set_style('darkgrid')\n",
    "bins = np.arange(0, 7500, 250).tolist()\n",
    "data['traffic_volume'].hist(bins=bins)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('traffic_volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Holiday**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check holidays included in the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holiday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Holiday distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['holiday'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with the holidays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holidays = data.loc[(data['holiday'] != 'None')]\n",
    "data_holidays.index = np.arange(1, len(data_holidays) + 1)\n",
    "data_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Holiday distribution (only holidays included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data_holidays['holiday'], y=data_holidays['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Temperature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Temperature distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['temp'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['temp'] <= 50)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Temperature distribution (without outliers)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['temp'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Rain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['rain_1h'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[(data['rain_1h'] >= 1000)]\n",
    "data = data.drop(outliers.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution (without outliers)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data['rain_1h'], y=data['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with rainy days*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rainy = data.loc[(data['rain_1h'] > 0)]\n",
    "#data_rainy = data.loc[(data['weather_main'] == \"Rain\")]\n",
    "data_rainy.index = np.arange(1, len(data_rainy) + 1)\n",
    "data_rainy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Rain distribution (only rainy days included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=data_rainy['rain_1h'], y=data_rainy['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Snow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Snow distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['snow_1h'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution only with snowy days*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snowy = data.loc[(data['snow_1h'] > 0)]\n",
    "#data_snowy = data.loc[(data['weather_main'] == \"Snow\")]\n",
    "data_snowy.index = np.arange(1, len(data_snowy) + 1)\n",
    "data_snowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Snow distribution (only snowy days included)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(data_snowy['snow_1h'], data_snowy['traffic_volume'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Cloud cover**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot of Traffic Volume vs Cloud cover distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25,15))\n",
    "\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax1.scatter(data['clouds_all'], data['traffic_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['clouds_all'].unique()\n",
    "#x = data['clouds_all'].value_counts()\n",
    "#y = list(x[:10].index)\n",
    "\n",
    "#plt.figure(figsize=(20, 8))\n",
    "#sns.boxplot(data['clouds_all'], data['traffic_volume'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Current weather**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Current weather distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['weather_main'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Volume vs Date time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Separation of the date elements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['year','month','day','hour','minutes','seconds']] = data['date_time'].str.extract(r'(\\d+)-(\\d+)-(\\d+)\\s*(\\d+):(\\d+):(\\d+)', expand=True)\n",
    "data = data.drop(['date_time'], axis=1)\n",
    "data[['year','month','day','hour','minutes','seconds']] = data[['year','month','day','hour','minutes','seconds']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset with new labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['year'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Month*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['month'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Box plot of Traffic Volume vs Hour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(x=data['hour'], y=data['traffic_volume'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drop minutes and second columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['minutes', 'seconds'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess Non Ordinal Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"weather_main\"])\n",
    "data = data.drop(\"weather_main\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"weather_description\"])\n",
    "data = data.drop(\"weather_description\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data[\"holiday\"])\n",
    "data = data.drop(\"holiday\",axis = 1)\n",
    "data = data.join(one_hot.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('traffic_volume', axis=1)\n",
    "y = data['traffic_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#split the data in attributes and class as well as training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Algorithms from Sklearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred1 = model.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred1))\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred1))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=3).fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Our regression algorithms*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "try:\n",
    "    del X_train['bias']\n",
    "except:\n",
    "    print('no bias to remove X_train')    \n",
    "try:\n",
    "    del X_test['bias']\n",
    "except:\n",
    "    print('no bias to remove X_test')\n",
    "try:\n",
    "    del X['bias']\n",
    "except:\n",
    "    print('no bias to remove X')\n",
    "\n",
    "\n",
    "import linearRegressionNumpy\n",
    "\n",
    "    \n",
    "#print('\\nMatrix Solution for Comparison:')\n",
    "#weightsMatrix = linearRegressionNumpy.matrixSolution(X_train, y_train)\n",
    "#yPredMatrix = linearRegressionNumpy.predictLinearRegression(X_test, weightsMatrix)\n",
    "#print('weights = ', weightsMatrix)\n",
    "\n",
    "\n",
    "print('\\n Now our own iterative regression algorithm:')    \n",
    "alpha = [] #[500, 500, 500, 500]\n",
    "alphaMethod = 'const'\n",
    "mu = 1\n",
    "convCritList = [1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "print('epsilon       | sum total error:   | sum relative error:  | iterations | Rsquare   ')\n",
    "for convergenceCriterion in convCritList:\n",
    "\n",
    "    weights, score, iterations = linearRegressionNumpy.linearRegression(X_train, y_train, alpha = alpha, mu = mu, \n",
    "                                                        convergenceCriterion = convergenceCriterion, lossFunction = 'MSE', \n",
    "                                                        alphaMethod = alphaMethod, printOutput = False)\n",
    "    yPred2 = linearRegressionNumpy.predictLinearRegression(X_test, weights)\n",
    "\n",
    "\n",
    "\n",
    "    print('{:13E} | {:19}| {:21}| {:11}| {:10}'.format(convergenceCriterion, \n",
    "                                        str(np.sum(yPred2-y_pred1)), \n",
    "                                        str(np.sum((yPred2-y_pred1)/y_pred1)),\n",
    "                                        str(iterations),\n",
    "                                        str(r2_score(y_test, yPred2))))\n",
    "    #print('sum total error: us iterative vs. scikit = ', np.sum(yPred2-y_pred1))\n",
    "    #print('sum relative error: us iterative vs. scikit = ', np.sum((yPred2-y_pred1)/y_pred1))\n",
    "\n",
    "print('yPred = ', yPred2)\n",
    "print('weights = ', weights)\n",
    "print('score = ', score)   \n",
    "    \n",
    "#print('\\n\\n\\n\\n\\n')\n",
    "\n",
    "plt.plot(y_pred1, label = 'scikit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(yPred2, label = 'us iterative solution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(yPredMatrix, label = 'us matrix solution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(yPred2-y_pred1, label = 'total error, us iterative vs. scikit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(yPredMatrix-y_pred1, label = 'total error, us matrix vs. scikit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(yPred2-yPredMatrix, label = 'total error, us iterative vs. us matrix')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot((yPred2-y_pred1)/y_pred1, label = 'relative error, us iterative vs. scikit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot((yPredMatrix-y_pred1)/y_pred1, label = 'relative error, us matrix vs. scikit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot((yPred2-yPredMatrix)/yPredMatrix, label = 'relative error, us vs. us matrix')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary creation to apply the mathematical functions of the algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = data.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecasting instances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1 # 1 = KNeighbors; 2 = RadiusNeighbors\n",
    "n_neighbours = 5\n",
    "distance_function = 1 # 1 = Euclidean Distance; 2 = Manhattan Distance\n",
    "radius = 0 # 0 indicates no radius\n",
    "label = 'traffic_volume'\n",
    "features = ['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(dictionary, label, features, mode, n_neighbours, distance_function, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution of the algorithm (forecasting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in y_test.index:\n",
    "    #print(x)\n",
    "    target = dictionary[x-1]\n",
    "    #print(target)\n",
    "    result = knn.run(target)\n",
    "    #print(result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(results,index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, predictions))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
