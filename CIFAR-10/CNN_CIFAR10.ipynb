{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLossesKeras\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cifar10(X_train, y_train, X_test, y_test):\n",
    "    for i in range(0, 9):  # Create a grid with 3x3 images\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(Image.fromarray(X_train[i]))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_cifar10_simple(num_classes, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_compile_model_cnn_cifar10_plus(num_classes, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_cifar10_plus_plus(num_classes, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_lenet5(num_classes, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def cifar10_using_cnn(mode, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # X_train = (50000, 32, 32, 3)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    \n",
    "    # Normalize inputs from 0-255 to 0.0-1.0\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    # Transform the label which is an integer into binary categories\n",
    "    # The value becomes that corresponding to the position, class 5 becomes the list [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "    \n",
    "    # Data Augmentation\n",
    "    if augmentation == True:\n",
    "        datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "        datagen.fit(X_train)\n",
    "\n",
    "    # Define the network topology and compile\n",
    "    epochs = 10\n",
    "    if mode == 0:\n",
    "        model = create_compile_model_cnn_cifar10_simple(num_classes, epochs)\n",
    "        print_model(model, \"model_cifar10_cnn_simple.png\")\n",
    "    elif mode == 1:\n",
    "        model = create_compile_model_cnn_cifar10_plus(num_classes, epochs)\n",
    "        print_model(model, \"model_cifar10_cnn_plus.png\")\n",
    "    elif mode == 2:\n",
    "        model = create_compile_model_cnn_cifar10_plus_plus(num_classes, epochs)\n",
    "        print_model(model, \"model_cifar10_cnn_plus_plus.png\")\n",
    "    elif mode == 3:\n",
    "        model = create_compile_model_cnn_cifar10_lenet5(num_classes, epochs)\n",
    "        print_model(model, \"model_cifar10_cnn_lenet5.png\")\n",
    "\n",
    "    #print(model.summary())\n",
    "    plotlosses = PlotLossesKeras()\n",
    "  \n",
    "    # Training the network\n",
    "    if augmentation == True:\n",
    "        history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=100), steps_per_epoch=len(X_train)/100, \n",
    "                            epochs=epochs, validation_data=(X_test, y_test), verbose=1, callbacks=[PlotLossesKeras()])\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=100, verbose=1, callbacks=[PlotLossesKeras()])\n",
    "\n",
    "    #print_history_accuracy(history)\n",
    "    #print_history_loss(history)\n",
    "\n",
    "    # Final evaluation with the test cases\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    #print('Scores: ', scores)\n",
    "    if mode == 0:\n",
    "        print(\"CNN model accuracy CIFAR10 simple: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss CIFAR10 simple: %.3f\" % (scores[0]))\n",
    "    elif mode == 1:\n",
    "        print(\"CNN model accuracy CIFAR10 plus: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss CIFAR10 plus: %.3f\" % (scores[0]))\n",
    "    elif mode == 2:\n",
    "        print(\"CNN model accuracy CIFAR10 plus plus: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss CIFAR10 plus plus: %.3f\" % (scores[0]))\n",
    "    elif mode == 3:\n",
    "        print(\"CNN model accuracy CIFAR10 lenet5: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss CIFAR10 lenet5: %.3f\" % (scores[0]))\n",
    "        \n",
    "\n",
    "# Useful to visualize the tipology of the network in pdf or png\n",
    "def print_model(model, fich):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "# Utils to visualize the history of the learning\n",
    "def print_history_accuracy(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_history_loss(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cifar10(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**augmentation: True or False**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mode: 0 -> simple; 1 -> plus; 2 -> plusplus; 3 -> lenet5;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "augmentation = True\n",
    "start_time = time.time()\n",
    "cifar10_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "augmentation = False\n",
    "start_time = time.time()\n",
    "cifar10_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "start_time = time.time()\n",
    "cifar10_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "start_time = time.time()\n",
    "cifar10_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 3\n",
    "start_time = time.time()\n",
    "cifar10_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
