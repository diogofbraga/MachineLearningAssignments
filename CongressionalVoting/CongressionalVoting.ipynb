{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Voting\n",
    "\n",
    "**Kaggle: 184.702 TU ML WS 20**\n",
    "\n",
    "**Goal: Predict the party of a congress member.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./184702-tu-ml-ws-20-congressional-voting/CongressionalVotingID.shuf.lrn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsTrain = data['ID'].to_frame()\n",
    "data = data.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace 'unknown' for a recognised variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\"unknown\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data per feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_feature = data.isnull().sum(axis=0)\n",
    "missing_values_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(missing_values_feature.axes[0].to_list(), missing_values_feature.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data per column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = data.isnull().sum() * 100 / len(data)\n",
    "missing_value_data_columns = pd.DataFrame({'percent_missing (%)': percent_missing})\n",
    "sort_data = missing_value_data_columns.copy()\n",
    "sort_data.sort_values('percent_missing (%)', inplace=True, ascending=False)\n",
    "sort_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove columns that have more than 30% (?) of missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = list(missing_value_data_columns.index[missing_value_data_columns['percent_missing (%)'] < 30])\n",
    "data = data[to_keep]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data per row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "percent_missing = (1 - data.apply(lambda x: x.count(), axis=1) / len(data.columns)) * 100\n",
    "missing_value_data_rows = pd.DataFrame({'percent_missing (%)': percent_missing})\n",
    "sort_data = missing_value_data_rows.copy()\n",
    "sort_data.sort_values('percent_missing (%)', inplace=True, ascending=False)\n",
    "sort_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove rows that have more than 50% (?) of missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 10)\n",
    "to_exclude = missing_value_data_rows[(missing_value_data_rows['percent_missing (%)'] >= 50)]\n",
    "data = data.drop(to_exclude.index)\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision: Replace missing values with the class mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for y in data.select_dtypes(include=['object']).columns.tolist():\n",
    "    mode_value = data[y].mode()\n",
    "    data[y] = data[y].fillna(mode_value[0])    \n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check no missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "ax = sns.countplot(x = data['class'])\n",
    "\n",
    "total = len(data['class'])\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:.1f}%'.format(100 * height/total),\n",
    "            ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class vs adoption-of-the-budget-resolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributeNames = ['handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze', 'el-salvador-aid', 'religious-groups-in-schools', 'anti-satellite-test-ban', 'aid-to-nicaraguan-contras', 'mx-missile', 'immigration', 'synfuels-crporation-cutback', 'education-spending', 'superfund-right-to-sue', 'crime', 'duty-free-exports', 'export-administration-act-south-africa']\n",
    "for i in range(0,len(attributeNames)):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.countplot(y = attributeNames[i], hue = \"class\", data = data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace 'n' and 'y' for a numeric value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\"n\", 0, inplace = True)\n",
    "data.replace(\"y\", 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class',axis=1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using mathematical function Z-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(X))\n",
    "threshold = 3\n",
    "outliers_rows = np.where(z > threshold)\n",
    "print(np.where(z > threshold))\n",
    "# The first array contains the list of row numbers and second array respective column numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(outliers_rows[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove the identified outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = X[(np.abs(stats.zscore(X)) < threshold).all(axis=1)]\n",
    "X_prepared = X_prepared.to_numpy()\n",
    "X_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.drop(outliers_rows[0])\n",
    "y = y.to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_prepared, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "kf = KFold(n_splits = n_folds, random_state = None, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Prediction\n",
    "\n",
    "**Types:**\n",
    "- Linear Classifiers: Logistic Regression, Naive Bayes Classifier\n",
    "- Nearest Neighbor\n",
    "- Support Vector Machines\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "d[\"Logistic Regression\"] = LogisticRegression()\n",
    "d[\"Gaussian Naive Bayes\"] = GaussianNB()\n",
    "\n",
    "d[\"KNearest Neighbors\"] = KNeighborsClassifier()\n",
    "\n",
    "d[\"SVM rbf\"] = SVC()\n",
    "d[\"SGD Classifier\"] = SGDClassifier()\n",
    "\n",
    "d[\"Decision Tree\"] = DecisionTreeClassifier()\n",
    "\n",
    "d[\"Random Forest\"] = RandomForestClassifier()\n",
    "\n",
    "d[\"Multi-layer Perceptron Classifier\"] = MLPClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoreList = []\n",
    "nameList = []\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, clf in d.items():\n",
    "    print(\"\\n--------------\",name,\"---------------\\n\")\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    final_score = 0\n",
    "    mislabeled_points = 0\n",
    "    for train_index, test_index in kf.split(X_prepared):\n",
    "        i = i+1\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_prepared[train_index], X_prepared[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        score = accuracy_score(y_test, predictions)\n",
    "        print(\"Fold\", i, 'Accuracy: {0:.2%}'.format(score),\\\n",
    "             \"-> %d mislabeled points of %d total points\"% ((y_test != predictions).sum(),X_test.shape[0]))\n",
    "        final_score = final_score + score\n",
    "        mislabeled_points = mislabeled_points + (y_test != predictions).sum()\n",
    "\n",
    "        if(i == n_folds):\n",
    "            end = time.time()\n",
    "            scoreList.append(final_score/n_folds)\n",
    "            nameList.append(name)\n",
    "            print('Final Accuracy: {0:.2%} -> Time: {1:.3} seconds'.format(final_score/n_folds, end - start),\\\n",
    "             \"-> %d mislabeled points of %d total points\\n\"% (mislabeled_points, X_prepared.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = sorted(zip(scoreList,nameList))[::-1]\n",
    "print(\"\\nClassifiers from best to worst:\")\n",
    "for i in range(0, len(ranking)):\n",
    "    print(i+1, ') {0:35} Score: {1:.2%}'.format(ranking[i][1], ranking[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestClassifierName = ranking[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bestClassifierName == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'penalty' : ['l1','l2'],\n",
    "        'C': [0.1, 1, 10], \n",
    "        'max_iter': [100, 1000]}\n",
    "    param_randomized = {\n",
    "        'penalty' : ['l1','l2'],\n",
    "        'C': uniform(loc=0, scale=10),\n",
    "        'max_iter': [100, 1000]}\n",
    "elif bestClassifierName == 'Gaussian Naive Bayes':\n",
    "    param_grid = {\n",
    "        'var_smoothing' : 10.0 ** -np.arange(6, 10)} \n",
    "    param_randomized = {}\n",
    "elif bestClassifierName == 'KNearest Neighbors':\n",
    "    param_grid = {\n",
    "        'n_neighbors' : [5, 10, 20, 50, 100, 200],\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'metric' : ['euclidean', 'manhattan']} \n",
    "    param_randomized = {\n",
    "        'n_neighbors' : uniform(loc=5, scale=200),\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'metric' : ['euclidean', 'manhattan']}\n",
    "elif bestClassifierName == 'SVM rbf':\n",
    "    param_grid = {\n",
    "        'class_weight': ['balanced', None], \n",
    "        'C': [0.1,1, 10, 100], \n",
    "        'gamma': [1,0.1,0.01,0.001], \n",
    "        'kernel': ['rbf', 'linear']} \n",
    "    param_randomized = {\n",
    "        'class_weight': ['balanced', None], \n",
    "        'C': uniform(loc=0, scale=100),\n",
    "        'gamma': uniform(loc=0.001, scale=1),\n",
    "        'kernel': ['rbf', 'linear']} \n",
    "elif bestClassifierName == 'SGD Classifier':\n",
    "    param_grid = {\n",
    "        'penalty' : ['l1','l2'],\n",
    "        'alpha' : 10.0 ** -np.arange(1, 5)} \n",
    "    param_randomized = {\n",
    "        'penalty' : ['l1','l2'],\n",
    "        'alpha' : uniform(loc=0.00001, scale=1)}\n",
    "elif bestClassifierName == 'Decision Tree':\n",
    "    param_grid = {\n",
    "        'criterion' : ['gini', 'entropy'],\n",
    "        'splitter' : ['best', 'random']} \n",
    "    param_randomized = {}\n",
    "elif bestClassifierName == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators' : [100, 200, 500, 1000],\n",
    "        'max_depth' : [1, 10, 20, None],\n",
    "        'bootstrap': [True, False]} \n",
    "    param_randomized = {} \n",
    "elif bestClassifierName == 'Multi-layer Perceptron Classifier':\n",
    "    param_grid = {\n",
    "        'activation': ['identity', 'logistic','tanh', 'relu'],\n",
    "        'max_iter': [500, 1000, 2000],\n",
    "        'alpha': 10.0 ** -np.arange(3, 7),\n",
    "        'hidden_layer_sizes': [50, 100, 200, 500]} \n",
    "    param_randomized = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf_gridsearch = GridSearchCV(d.get(bestClassifierName), param_grid, verbose=0)\n",
    "clf_gridsearch.fit(X_train, y_train)\n",
    "print(clf_gridsearch.best_params_)\n",
    "predictions = clf_gridsearch.predict(X_test)\n",
    "score_gridsearch = accuracy_score(y_test, predictions)\n",
    "end = time.time()\n",
    "print(bestClassifierName, \"GridSearchCV - Accuracy: %0.3f\" % score_gridsearch, \"- Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf_randomizedsearch = RandomizedSearchCV(d.get(bestClassifierName), param_randomized, random_state=0)\n",
    "clf_randomizedsearch.fit(X_train, y_train)\n",
    "print(clf_randomizedsearch.best_params_)\n",
    "predictions = clf_randomizedsearch.predict(X_test)\n",
    "score_randomizedsearch = accuracy_score(y_test, predictions)\n",
    "end = time.time()\n",
    "print(bestClassifierName, \"RandomizedSearchCV - Accuracy: %0.3f\" % score_randomizedsearch, \"- Time: %0.2f\" % (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get(ranking[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ranking[0][0] > score_gridsearch and ranking[0][0] > score_randomizedsearch:\n",
    "    print(\"Not optimized\")\n",
    "    clf = d.get(ranking[0][1])\n",
    "elif score_gridsearch > score_randomizedsearch:\n",
    "    clf = clf_gridsearch.best_estimator_\n",
    "else:\n",
    "    clf = clf_randomizedsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Classifier with Hyper Parametrization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit Classifier & Predict in all Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# clf -> best estimator\n",
    "predictions = cross_val_predict(clf, X_prepared, y, cv=5)\n",
    "score = accuracy_score(y, predictions)\n",
    "end = time.time()\n",
    "print('Accuracy Training Data: {0:.2%} - Time: {1:.3} seconds\\n'.format(score, end - start))\n",
    "\n",
    "#print(confusion_matrix(y, predictions))\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('./184702-tu-ml-ws-20-congressional-voting/CongressionalVotingID.shuf.tes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.replace(\"unknown\", np.nan, inplace = True)\n",
    "\n",
    "for i in testData.select_dtypes(include=['object']).columns.tolist():\n",
    "    mode_value = testData[i].mode()\n",
    "    testData[i] = testData[i].fillna(mode_value[0])  \n",
    "    \n",
    "testData.replace(\"n\", 0, inplace = True)\n",
    "testData.replace(\"y\", 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove identifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsTest = testData['ID'].to_frame()\n",
    "testData = testData.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join IDs to create Submission Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions, columns=['Class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([idsTest,predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
