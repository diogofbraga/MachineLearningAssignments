{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "#TensorFlow: Channels last order.\n",
    "#Theano: Channels first order.\n",
    "#CNTK: Channels last order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio as im\n",
    "from keras import models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf') \n",
    "K.image_data_format() == 'channels_last'\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 6 images of FashionMNIST in a gray scale\n",
    "def visualize_fashion_mnist(X_train):\n",
    "    plt.subplot(321)\n",
    "    plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(322)\n",
    "    plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(323)\n",
    "    plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(324)\n",
    "    plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(325)\n",
    "    plt.imshow(X_train[4], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(326)\n",
    "    plt.imshow(X_train[5], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    \n",
    "def data_preparation():\n",
    "    \n",
    "    ((X_train, y_train), (X_test, y_test)) = fashion_mnist.load_data()\n",
    "    \n",
    "    visualize_fashion_mnist(X_train)\n",
    "    \n",
    "    # Transform to the format [instances][width][height][pixels]\n",
    "    # (60000, 28, 28)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "    # (60000, 28, 28, 1)\n",
    "\n",
    "    # Normalize the pixel values from 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    # Transform the label which is an integer into binary categories\n",
    "    # The value becomes that corresponding to the position, class 5 becomes the list [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, num_classes\n",
    "\n",
    "X_train, X_test, y_train, y_test, num_classes = data_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_cnn_simple(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def create_model_cnn_plus(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def create_model_cnn_plus_plus(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape = (28, 28, 1), activation = 'relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "def create_model_cnn_lenet5(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = create_model_cnn_plus(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"best_weights_fashion_mnist.hdf5\", monitor = 'val_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=200, verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_weights_fashion_mnist.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save:\n",
    "model.save('fashion_mnist_cnn.h5')\n",
    "#model.save('fashion_mnist_cnn.h5')\n",
    "\n",
    "# To use:\n",
    "#model=load_model('fashion_mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils to visualize the history of the learning\n",
    "def print_history_accuracy(history):\n",
    "    #print(history.history.keys())\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def print_history_loss(history):\n",
    "    #print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "print_history_accuracy(history)\n",
    "print_history_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View image, label and corresponding prediction\n",
    "def visualize_prediction(x_test, y_test, img_to_show):\n",
    "    print(\"X_test:\",x_test.shape)\n",
    "    print(\"y_test:\",y_test.shape)\n",
    "    print(\"Image:\",x_test[img_to_show].shape)\n",
    "    plt.imshow(x_test[img_to_show,:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Label:\",y_test[img_to_show])\n",
    "    print(\"Before increasing another dimension:\",x_test[img_to_show].shape)\n",
    "    image_tensor = np.expand_dims(x_test[img_to_show], axis=0)\n",
    "    print(\"After increasing another dimension:\",image_tensor.shape)\n",
    "    print(\"Prediction:\",model.predict(image_tensor))\n",
    "    classes = model.predict_classes(image_tensor)\n",
    "    print('Predicted Class:',classes)\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "image_tensor = visualize_prediction(X_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuremaps Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the outputs of the first 5 (plus) layers of the network or 12 for plus_plus\n",
    "output_layers = []\n",
    "for layer in model.layers[:5]:\n",
    "    print(layer.output.shape)\n",
    "    output_layers.append(layer.output)\n",
    "\n",
    "# And then we create a model that returns these outputs given the model inputs\n",
    "activation_model = models.Model(inputs=model.input, outputs=output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(image_tensor) \n",
    "# Returns a list of two Numpy arrays: one array per activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(first_layer_activation[0, :, :, 9], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_names = []\n",
    "for layer in model.layers[:5]:\n",
    "    layers_names.append(layer.name)\n",
    "    \n",
    "images_per_line = int(first_layer_activation.shape[3] / 2)\n",
    "\n",
    "for layer_name, activation_layer in zip(layers_names, activations):\n",
    "    n_features = activation_layer.shape[-1]\n",
    "    size = activation_layer.shape[1]\n",
    "    n_lines = -(-n_features // images_per_line)\n",
    "    print(\"layer_name:\",layer_name)\n",
    "    print(\"n_features:\",n_features)\n",
    "    print(\"size:\",size)\n",
    "    print(\"n_lines:\",n_lines)\n",
    "    display_grid = np.zeros((size * n_lines, images_per_line * size))\n",
    "    for col in range(n_lines):\n",
    "        for lin in range(images_per_line):\n",
    "            image = activation_layer[0,:,:,col * images_per_line + lin]\n",
    "            image -= image.mean()\n",
    "            image /= image.std()\n",
    "            image *= 64\n",
    "            image += 128\n",
    "            image = np.clip(image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,lin * size : (lin + 1) * size] = image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
