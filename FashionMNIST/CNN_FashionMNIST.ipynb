{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, MaxPool2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 6 images of FashionMNIST in a gray scale\n",
    "def visualize_fashion_mnist(X_train, y_train, X_test, y_test):\n",
    "    plt.subplot(321)\n",
    "    plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(322)\n",
    "    plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(323)\n",
    "    plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(324)\n",
    "    plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(325)\n",
    "    plt.imshow(X_train[4], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(326)\n",
    "    plt.imshow(X_train[5], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_simple(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_plus(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_compile_model_cnn_plus_plus(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape = (28, 28, 1), activation = 'relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_compile_model_cnn_lenet5(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def fashion_mnist_using_cnn(mode, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Transform to the format [instances][width][height][pixels]\n",
    "    # (60000, 28, 28)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "    # (60000, 28, 28, 1)\n",
    "\n",
    "    # Normalize the pixel values from 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    # Transform the label which is an integer into binary categories\n",
    "    # The value becomes that corresponding to the position, class 5 becomes the list [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "\n",
    "    # Data Augmentation\n",
    "    if augmentation == True:\n",
    "        datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "        datagen.fit(X_train)\n",
    "    \n",
    "    # Define the network topology and compile\n",
    "    epochs = 10\n",
    "    if mode == 0:\n",
    "        model = create_compile_model_cnn_simple(num_classes)\n",
    "        print_model(model, \"model_fashion_mnist_cnn_simples.png\")\n",
    "    elif mode == 1:\n",
    "        model = create_compile_model_cnn_plus(num_classes)\n",
    "        print_model(model, \"model_fashion_mnist_cnn_plus.png\")\n",
    "    elif mode == 2:\n",
    "        model = create_compile_model_cnn_plus_plus(num_classes)\n",
    "        print_model(model, \"model_fashion_mnist_cnn_plus_plus.png\")\n",
    "    elif mode == 3:\n",
    "        model = create_compile_model_cnn_lenet5(num_classes)\n",
    "        print_model(model, \"model_fashion_mnist_cnn_lenet5.png\")\n",
    "\n",
    "    #print(model.summary())\n",
    "    plotlosses = PlotLossesKeras()\n",
    "    \n",
    "    # Training the network\n",
    "    if augmentation == True:\n",
    "        history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=100), steps_per_epoch=len(X_train)/100, \n",
    "                            epochs=epochs, validation_data=(X_test, y_test), verbose=1, callbacks=[PlotLossesKeras()])\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=100, verbose=1, callbacks=[PlotLossesKeras()])\n",
    "    \n",
    "    #print_history_accuracy(history)\n",
    "    #print_history_loss(history)\n",
    "\n",
    "    # Final evaluation with the test cases\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    #print('Scores: ', scores)\n",
    "    if mode == 0:\n",
    "        print(\"CNN model accuracy FashionMNIST simple: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss FashionMNIST simple: %.3f\" % (scores[0]))\n",
    "    elif mode == 1:\n",
    "        print(\"CNN model accuracy FashionMNIST plus: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss FashionMNIST plus: %.3f\" % (scores[0]))\n",
    "    elif mode == 2:\n",
    "        print(\"CNN model accuracy FashionMNIST plus plus: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss FashionMNIST plus plus: %.3f\" % (scores[0]))\n",
    "    elif mode == 3:\n",
    "        print(\"CNN model accuracy FashionMNIST lenet5: %.2f%%\" % (scores[1]*100))\n",
    "        print(\"CNN model loss FashionMNIST lenet5: %.3f\" % (scores[0]))\n",
    "        \n",
    "\n",
    "# Useful to visualize the tipology of the network in pdf or png\n",
    "def print_model(model, fich):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "# Utils to visualize the history of the learning\n",
    "def print_history_accuracy(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_history_loss(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_fashion_mnist(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**augmentation: True or False**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mode: 0 -> simple; 1 -> plus; 2 -> plusplus; 3 -> lenet5;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "augmentation = True\n",
    "start_time = time.time()\n",
    "fashion_mnist_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "augmentation = False\n",
    "start_time = time.time()\n",
    "fashion_mnist_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "start_time = time.time()\n",
    "fashion_mnist_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "start_time = time.time()\n",
    "fashion_mnist_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 3\n",
    "start_time = time.time()\n",
    "fashion_mnist_using_cnn(mode, x_train, y_train, x_test, y_test)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(\"Processing Time: %.3f seconds\" % (time_taken))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
